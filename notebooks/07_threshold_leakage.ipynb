{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": "# Threshold and Regime Leakage\n\n## Computing Percentiles and Regimes Without Lookahead\n\n---\n\n## üö® If You Know sklearn But Not Regime Classification, Read This First\n\n**What you already know (from standard ML)**:\n- Thresholds are just numbers you pick\n- Percentiles help you understand data distribution\n- Classification boundaries are features like any other\n\n**What's different with time series regimes**:\n\nIn time series, we classify observations into **regimes**:\n- UP/DOWN/FLAT based on move magnitude\n- HIGH/MEDIUM/LOW volatility periods\n\n**The trap**: The threshold that *defines* these regimes is itself information!\n\n```python\n# SEEMS INNOCENT:\nthreshold = np.percentile(np.abs(y), 70)  # 70th percentile of all changes\n\n# ACTUALLY LEAKY:\n# This threshold uses FUTURE changes to classify PAST observations!\n# The threshold \"knows\" what volatility looks like in the test period.\n```\n\n**Real-world example (BUG-005)**:\n\nA team classified volatility using `std(levels)` instead of `std(changes)`:\n- A steady 3% drift series was labeled \"HIGH volatility\" (values spread 3.0 ‚Üí 4.0)\n- Actually, it was the most PREDICTABLE series (constant drift = easy to forecast)\n- Model looked great in \"HIGH volatility\" regime (because it wasn't actually volatile!)\n\n**The fix**: Use `basis='changes'` and compute thresholds from training only.\n\n---\n\n**What you'll learn:**\n1. Why computing thresholds from the full series creates subtle leakage\n2. How to compute move thresholds correctly from training data\n3. The BUG-005 volatility basis error and why `basis='changes'` matters\n4. How regime stratification exposes hidden model failures\n\n**Prerequisites:** Notebooks 01, 05, 06\n\n---"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from temporalcv.cv import WalkForwardCV\n",
    "from temporalcv.gates import gate_shuffled_target, gate_suspicious_improvement, GateStatus\n",
    "\n",
    "# Check if regimes module is available\n",
    "try:\n",
    "    from temporalcv.regimes import classify_volatility_regime, classify_direction_regime\n",
    "    HAS_REGIMES = True\n",
    "except ImportError:\n",
    "    HAS_REGIMES = False\n",
    "    print(\"Note: regimes module not available. Using local implementations.\")\n",
    "\n",
    "np.random.seed(42)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate AR(1) process with regime-like behavior\n",
    "def generate_ar1(n=500, phi=0.9, sigma=1.0, seed=42):\n",
    "    \"\"\"Generate AR(1) process.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    y = np.zeros(n)\n",
    "    y[0] = rng.normal(0, sigma / np.sqrt(1 - phi**2))\n",
    "    for t in range(1, n):\n",
    "        y[t] = phi * y[t-1] + sigma * rng.normal()\n",
    "    return y\n",
    "\n",
    "def generate_regime_switching(n=600, seed=42):\n",
    "    \"\"\"Generate series with known regime changes (volatility shifts).\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    y = np.zeros(n)\n",
    "    \n",
    "    # Three regimes: LOW (0-200), HIGH (200-400), LOW (400-600)\n",
    "    sigma_low, sigma_high = 0.5, 2.0\n",
    "    phi = 0.9\n",
    "    \n",
    "    y[0] = rng.normal(0, sigma_low)\n",
    "    for t in range(1, n):\n",
    "        if t < 200 or t >= 400:\n",
    "            sigma = sigma_low\n",
    "        else:\n",
    "            sigma = sigma_high\n",
    "        y[t] = phi * y[t-1] + sigma * rng.normal()\n",
    "    \n",
    "    return y\n",
    "\n",
    "# Generate data\n",
    "series = generate_ar1(n=600, phi=0.9, seed=42)\n",
    "series_regime = generate_regime_switching(n=600, seed=42)\n",
    "\n",
    "print(f\"Generated standard series: {len(series)} observations\")\n",
    "print(f\"Generated regime-switching series: {len(series_regime)} observations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 1: Move Threshold Leakage\n",
    "\n",
    "### The Problem\n",
    "\n",
    "The **move threshold** (typically 70th percentile of |changes|) defines what counts as a significant move (UP or DOWN vs FLAT).\n",
    "\n",
    "```python\n",
    "# WRONG: Threshold from full series\n",
    "threshold = np.percentile(np.abs(y_all), 70)\n",
    "\n",
    "# Bug: This threshold uses test data information!\n",
    "```\n",
    "\n",
    "### Why It Matters [T2]\n",
    "\n",
    "The 70th percentile threshold (per SPECIFICATION.md) determines:\n",
    "- Which observations are classified as UP/DOWN/FLAT\n",
    "- How MC-SS (Move-Conditional Skill Score) is computed\n",
    "- Which regime-stratified metrics are applied\n",
    "\n",
    "If computed from full data, you're using future volatility information to classify past observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute changes\n",
    "changes = np.diff(series)\n",
    "split_idx = 400  # 400 train, ~200 test\n",
    "\n",
    "# WRONG: Threshold from full series\n",
    "threshold_wrong = np.percentile(np.abs(changes), 70)\n",
    "\n",
    "# RIGHT: Threshold from training only\n",
    "threshold_right = np.percentile(np.abs(changes[:split_idx]), 70)\n",
    "\n",
    "print(\"MOVE THRESHOLD COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nSplit index: {split_idx}\")\n",
    "print(f\"Training observations: {split_idx}\")\n",
    "print(f\"Test observations: {len(changes) - split_idx}\")\n",
    "print(f\"\\nThreshold (WRONG - full series):   {threshold_wrong:.4f}\")\n",
    "print(f\"Threshold (RIGHT - training only): {threshold_right:.4f}\")\n",
    "print(f\"\\nDifference: {abs(threshold_wrong - threshold_right):.4f}\")\n",
    "print(f\"  ({abs(threshold_wrong - threshold_right) / threshold_right * 100:.1f}% relative difference)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show how classification differs\n",
    "def classify_moves(changes, threshold):\n",
    "    \"\"\"Classify moves as UP, DOWN, or FLAT.\"\"\"\n",
    "    labels = np.array(['FLAT'] * len(changes))\n",
    "    labels[changes > threshold] = 'UP'\n",
    "    labels[changes < -threshold] = 'DOWN'\n",
    "    return labels\n",
    "\n",
    "# Classify test period with both thresholds\n",
    "test_changes = changes[split_idx:]\n",
    "\n",
    "labels_wrong = classify_moves(test_changes, threshold_wrong)\n",
    "labels_right = classify_moves(test_changes, threshold_right)\n",
    "\n",
    "print(\"CLASSIFICATION COMPARISON (Test Period)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for label in ['UP', 'DOWN', 'FLAT']:\n",
    "    n_wrong = np.sum(labels_wrong == label)\n",
    "    n_right = np.sum(labels_right == label)\n",
    "    diff = n_wrong - n_right\n",
    "    print(f\"  {label:<6}: Wrong={n_wrong:<4} Right={n_right:<4} Diff={diff:+d}\")\n",
    "\n",
    "# How many observations changed classification?\n",
    "n_changed = np.sum(labels_wrong != labels_right)\n",
    "print(f\"\\nObservations with different classification: {n_changed}\")\n",
    "print(f\"  ({n_changed / len(labels_wrong) * 100:.1f}% of test period)\")\n",
    "print(f\"\\nThese classification differences are LEAKAGE.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the impact on regime classification\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8), sharex=True)\n",
    "\n",
    "t = np.arange(len(changes))\n",
    "\n",
    "# Top: Full series with thresholds\n",
    "ax = axes[0]\n",
    "ax.plot(t, changes, 'b-', alpha=0.6, linewidth=0.8)\n",
    "ax.axhline(y=threshold_wrong, color='red', linestyle='--', linewidth=2,\n",
    "           label=f'WRONG threshold: {threshold_wrong:.3f}')\n",
    "ax.axhline(y=-threshold_wrong, color='red', linestyle='--', linewidth=2)\n",
    "ax.axhline(y=threshold_right, color='green', linestyle='-', linewidth=2,\n",
    "           label=f'RIGHT threshold: {threshold_right:.3f}')\n",
    "ax.axhline(y=-threshold_right, color='green', linestyle='-', linewidth=2)\n",
    "ax.axvline(x=split_idx, color='black', linestyle=':', linewidth=2, label='Train/Test split')\n",
    "ax.set_ylabel('Change', fontsize=11)\n",
    "ax.set_title('Move Thresholds: WRONG (full series) vs RIGHT (training only)',\n",
    "             fontsize=13, fontweight='bold')\n",
    "ax.legend(loc='upper right')\n",
    "\n",
    "# Bottom: Classification differences\n",
    "ax = axes[1]\n",
    "# Color by whether classification differs\n",
    "colors = np.where(labels_wrong != labels_right, 'red', 'gray')\n",
    "ax.scatter(t[split_idx:], test_changes, c=colors, s=10, alpha=0.7)\n",
    "ax.axhline(y=0, color='black', linewidth=0.5)\n",
    "ax.axvline(x=split_idx, color='black', linestyle=':', linewidth=2)\n",
    "ax.set_xlabel('Time Index', fontsize=11)\n",
    "ax.set_ylabel('Change', fontsize=11)\n",
    "ax.set_title('Test Period: Red = Different Classification (Leakage Impact)',\n",
    "             fontsize=12, fontweight='bold', color='red')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 2: BUG-005 ‚Äî Volatility Basis Error [T3]\n",
    "\n",
    "### The Problem\n",
    "\n",
    "When computing volatility regimes, the **basis** matters critically:\n",
    "\n",
    "- `basis='levels'`: Computes std of the series levels ‚Üí **WRONG for drift**\n",
    "- `basis='changes'`: Computes std of the changes ‚Üí **CORRECT**\n",
    "\n",
    "### Why It Matters\n",
    "\n",
    "Consider a series with steady drift (e.g., 3.0 ‚Üí 4.0 over 100 periods):\n",
    "- **std(levels)** is HIGH because values range from 3.0 to 4.0\n",
    "- **std(changes)** is LOW because each change is approximately +0.01\n",
    "\n",
    "The first definition is misleading ‚Äî the series is **predictable** (steady drift), not volatile!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate BUG-005: volatility basis error\n",
    "def generate_steady_drift(n=100, drift_per_step=0.01, noise=0.001, seed=42):\n",
    "    \"\"\"Generate series with steady drift but low volatility.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    y = np.cumsum(np.ones(n) * drift_per_step + rng.normal(0, noise, n))\n",
    "    return y + 3.0  # Start at 3.0\n",
    "\n",
    "def generate_high_volatility(n=100, sigma=0.1, seed=42):\n",
    "    \"\"\"Generate stationary series with high volatility.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    return 3.5 + rng.normal(0, sigma, n)\n",
    "\n",
    "# Generate two contrasting series\n",
    "drift_series = generate_steady_drift(n=100)\n",
    "volatile_series = generate_high_volatility(n=100)\n",
    "\n",
    "print(\"BUG-005: Volatility Basis Comparison\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Compute volatility both ways\n",
    "print(\"\\nSeries 1: Steady Drift (predictable)\")\n",
    "print(f\"  std(levels):  {np.std(drift_series):.4f}  ‚Üê Looks HIGH\")\n",
    "print(f\"  std(changes): {np.std(np.diff(drift_series)):.4f}  ‚Üê Actually LOW\")\n",
    "\n",
    "print(\"\\nSeries 2: Stationary Noise (unpredictable)\")\n",
    "print(f\"  std(levels):  {np.std(volatile_series):.4f}  ‚Üê Moderate\")\n",
    "print(f\"  std(changes): {np.std(np.diff(volatile_series)):.4f}  ‚Üê Actually HIGH\")\n",
    "\n",
    "print(\"\\n[T3] The WRONG basis (levels) would classify steady drift as HIGH volatility!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the two series\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "\n",
    "# Top: Drift series\n",
    "axes[0, 0].plot(drift_series, 'b-', linewidth=1.5)\n",
    "axes[0, 0].set_title('Steady Drift: Levels', fontsize=11, fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Value')\n",
    "axes[0, 0].annotate(f'std(levels) = {np.std(drift_series):.3f}\\n(LOOKS high)',\n",
    "                    xy=(0.7, 0.3), xycoords='axes fraction', fontsize=10, color='red')\n",
    "\n",
    "axes[0, 1].plot(np.diff(drift_series), 'b-', linewidth=1.5)\n",
    "axes[0, 1].axhline(y=0, color='gray', linestyle='--')\n",
    "axes[0, 1].set_title('Steady Drift: Changes', fontsize=11, fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Change')\n",
    "axes[0, 1].annotate(f'std(changes) = {np.std(np.diff(drift_series)):.4f}\\n(Actually LOW)',\n",
    "                    xy=(0.7, 0.3), xycoords='axes fraction', fontsize=10, color='green')\n",
    "\n",
    "# Bottom: Volatile series\n",
    "axes[1, 0].plot(volatile_series, 'r-', linewidth=1.5)\n",
    "axes[1, 0].set_title('Stationary Noise: Levels', fontsize=11, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Time')\n",
    "axes[1, 0].set_ylabel('Value')\n",
    "axes[1, 0].annotate(f'std(levels) = {np.std(volatile_series):.3f}',\n",
    "                    xy=(0.7, 0.3), xycoords='axes fraction', fontsize=10)\n",
    "\n",
    "axes[1, 1].plot(np.diff(volatile_series), 'r-', linewidth=1.5)\n",
    "axes[1, 1].axhline(y=0, color='gray', linestyle='--')\n",
    "axes[1, 1].set_title('Stationary Noise: Changes', fontsize=11, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Time')\n",
    "axes[1, 1].set_ylabel('Change')\n",
    "axes[1, 1].annotate(f'std(changes) = {np.std(np.diff(volatile_series)):.4f}\\n(Actually HIGH)',\n",
    "                    xy=(0.7, 0.3), xycoords='axes fraction', fontsize=10, color='red')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey insight: Use basis='changes' to measure TRUE volatility (unpredictability).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement correct volatility classification\n",
    "def classify_volatility_regime_local(values, window=13, basis='changes',\n",
    "                                     low_percentile=33, high_percentile=67):\n",
    "    \"\"\"\n",
    "    Classify each observation into LOW, MEDIUM, or HIGH volatility regime.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    values : array-like\n",
    "        Time series values\n",
    "    window : int, default=13\n",
    "        Rolling window for volatility calculation (13 weeks ‚âà quarterly) [T3]\n",
    "    basis : {'changes', 'levels'}, default='changes'\n",
    "        Whether to compute volatility from changes or levels.\n",
    "        CRITICAL: Use 'changes' to avoid BUG-005.\n",
    "    low_percentile : float, default=33\n",
    "        Percentile below which volatility is LOW [T2]\n",
    "    high_percentile : float, default=67\n",
    "        Percentile above which volatility is HIGH [T2]\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    regimes : array\n",
    "        Regime labels: 'LOW', 'MEDIUM', or 'HIGH'\n",
    "    \"\"\"\n",
    "    values = np.asarray(values)\n",
    "    n = len(values)\n",
    "    \n",
    "    # Compute what we're measuring volatility of\n",
    "    if basis == 'changes':\n",
    "        vol_input = np.abs(np.diff(values))\n",
    "        # Pad to match original length\n",
    "        vol_input = np.concatenate([[np.nan], vol_input])\n",
    "    else:  # basis == 'levels' (WRONG for most use cases)\n",
    "        vol_input = values\n",
    "    \n",
    "    # Rolling volatility\n",
    "    rolling_vol = pd.Series(vol_input).rolling(window, min_periods=1).std().values\n",
    "    \n",
    "    # Compute thresholds (from the data we have)\n",
    "    valid_vol = rolling_vol[~np.isnan(rolling_vol)]\n",
    "    low_thresh = np.percentile(valid_vol, low_percentile)\n",
    "    high_thresh = np.percentile(valid_vol, high_percentile)\n",
    "    \n",
    "    # Classify\n",
    "    regimes = np.array(['MEDIUM'] * n)\n",
    "    regimes[rolling_vol < low_thresh] = 'LOW'\n",
    "    regimes[rolling_vol > high_thresh] = 'HIGH'\n",
    "    \n",
    "    return regimes\n",
    "\n",
    "# Test on regime-switching series\n",
    "regimes_right = classify_volatility_regime_local(series_regime, basis='changes')\n",
    "regimes_wrong = classify_volatility_regime_local(series_regime, basis='levels')\n",
    "\n",
    "print(\"Volatility Regime Classification\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nSeries has known regime changes at t=200 and t=400\")\n",
    "print(f\"  t=0-200: LOW volatility\")\n",
    "print(f\"  t=200-400: HIGH volatility\")\n",
    "print(f\"  t=400-600: LOW volatility\")\n",
    "\n",
    "print(f\"\\nClassification counts (basis='changes' - CORRECT):\")\n",
    "for regime in ['LOW', 'MEDIUM', 'HIGH']:\n",
    "    print(f\"  {regime}: {np.sum(regimes_right == regime)}\")\n",
    "\n",
    "print(f\"\\nClassification counts (basis='levels' - WRONG):\")\n",
    "for regime in ['LOW', 'MEDIUM', 'HIGH']:\n",
    "    print(f\"  {regime}: {np.sum(regimes_wrong == regime)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 3: Regime Stratification Exposes Hidden Failures\n",
    "\n",
    "### The Insight\n",
    "\n",
    "A model might **pass overall** but **fail in specific regimes**.\n",
    "\n",
    "- Overall MAE looks good\n",
    "- But HIGH volatility regime has terrible performance\n",
    "- Or FLAT regime has artificially good metrics (persistence works)\n",
    "\n",
    "**Stratification** reveals these hidden issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model that works well on average but fails in HIGH regime\n",
    "def create_lag_features(series, n_lags=5):\n",
    "    \"\"\"Create lag features.\"\"\"\n",
    "    n = len(series)\n",
    "    X = np.column_stack([\n",
    "        np.concatenate([[np.nan]*lag, series[:-lag]]) \n",
    "        for lag in range(1, n_lags + 1)\n",
    "    ])\n",
    "    valid = ~np.isnan(X).any(axis=1)\n",
    "    return X[valid], series[valid]\n",
    "\n",
    "# Use regime-switching series\n",
    "X, y = create_lag_features(series_regime, n_lags=5)\n",
    "regimes = classify_volatility_regime_local(series_regime, basis='changes')[5:]  # Align\n",
    "\n",
    "# Train/test split\n",
    "split_idx = int(len(X) * 0.7)\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "regimes_test = regimes[split_idx:]\n",
    "\n",
    "# Train model\n",
    "model = Ridge(alpha=1.0)\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "# Evaluate overall\n",
    "overall_mae = mean_absolute_error(y_test, preds)\n",
    "persist_mae = mean_absolute_error(y_test, X_test[:, 0])  # Persistence: y[t-1]\n",
    "\n",
    "print(\"OVERALL vs STRATIFIED EVALUATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nOverall Performance:\")\n",
    "print(f\"  Model MAE:       {overall_mae:.4f}\")\n",
    "print(f\"  Persistence MAE: {persist_mae:.4f}\")\n",
    "improvement = (persist_mae - overall_mae) / persist_mae * 100\n",
    "print(f\"  Improvement: {improvement:.1f}%\")\n",
    "\n",
    "# Evaluate by regime\n",
    "print(f\"\\nStratified Performance:\")\n",
    "for regime in ['LOW', 'MEDIUM', 'HIGH']:\n",
    "    mask = regimes_test == regime\n",
    "    if np.sum(mask) > 0:\n",
    "        regime_mae = mean_absolute_error(y_test[mask], preds[mask])\n",
    "        regime_persist = mean_absolute_error(y_test[mask], X_test[mask, 0])\n",
    "        regime_improvement = (regime_persist - regime_mae) / regime_persist * 100\n",
    "        print(f\"  {regime:6s}: n={np.sum(mask):3d}, MAE={regime_mae:.4f}, \"\n",
    "              f\"Improvement={regime_improvement:+.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize stratified performance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: Predictions by regime\n",
    "ax = axes[0]\n",
    "t = np.arange(len(y_test))\n",
    "\n",
    "for regime, color in [('LOW', 'green'), ('MEDIUM', 'orange'), ('HIGH', 'red')]:\n",
    "    mask = regimes_test == regime\n",
    "    ax.scatter(t[mask], y_test[mask] - preds[mask], c=color, alpha=0.5, s=20, label=regime)\n",
    "\n",
    "ax.axhline(y=0, color='black', linestyle='--', linewidth=0.5)\n",
    "ax.set_xlabel('Test Index')\n",
    "ax.set_ylabel('Error (Actual - Predicted)')\n",
    "ax.set_title('Prediction Errors by Volatility Regime', fontsize=12, fontweight='bold')\n",
    "ax.legend()\n",
    "\n",
    "# Right: MAE by regime (bar chart)\n",
    "ax = axes[1]\n",
    "regimes_list = ['LOW', 'MEDIUM', 'HIGH']\n",
    "maes = []\n",
    "persist_maes = []\n",
    "for regime in regimes_list:\n",
    "    mask = regimes_test == regime\n",
    "    if np.sum(mask) > 0:\n",
    "        maes.append(mean_absolute_error(y_test[mask], preds[mask]))\n",
    "        persist_maes.append(mean_absolute_error(y_test[mask], X_test[mask, 0]))\n",
    "    else:\n",
    "        maes.append(0)\n",
    "        persist_maes.append(0)\n",
    "\n",
    "x = np.arange(len(regimes_list))\n",
    "width = 0.35\n",
    "ax.bar(x - width/2, maes, width, label='Model', color='steelblue')\n",
    "ax.bar(x + width/2, persist_maes, width, label='Persistence', color='gray', alpha=0.7)\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(regimes_list)\n",
    "ax.set_ylabel('MAE')\n",
    "ax.set_title('MAE by Volatility Regime', fontsize=12, fontweight='bold')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nStratification reveals how the model performs in different conditions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 4: Correct Threshold Computation\n",
    "\n",
    "### The Rule\n",
    "\n",
    "**All thresholds must be computed from TRAINING data only.**\n",
    "\n",
    "```python\n",
    "# WRONG\n",
    "threshold = np.percentile(np.abs(y_all), 70)\n",
    "\n",
    "# RIGHT\n",
    "threshold = np.percentile(np.abs(y_train), 70)\n",
    "```\n",
    "\n",
    "### Inside CV Folds\n",
    "\n",
    "```python\n",
    "for train_idx, test_idx in cv.split(X, y):\n",
    "    # Compute threshold from THIS fold's training data\n",
    "    fold_threshold = np.percentile(np.abs(y[train_idx]), 70)\n",
    "    \n",
    "    # Apply to both train and test\n",
    "    train_regimes = classify_moves(y[train_idx], fold_threshold)\n",
    "    test_regimes = classify_moves(y[test_idx], fold_threshold)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": "# Complete workflow with correct threshold handling\n#\n# ‚ö†Ô∏è CRITICAL: LAG OFFSET ALIGNMENT\n# When we create lag features with n_lags=5, we lose the first 5 observations.\n# The indices from cv.split(X) are relative to X, not the original series!\n# We must track this offset when mapping back to original series indices.\n\nN_LAGS = 5  # Define constant for clarity\n\ndef evaluate_with_correct_thresholds(series, n_splits=5, window=13, n_lags=N_LAGS):\n    \"\"\"\n    Evaluate model with thresholds computed correctly per fold.\n    \n    Note on index alignment:\n        - create_lag_features drops first n_lags observations\n        - CV indices are relative to the feature matrix X, not original series\n        - Original series index = X index + n_lags\n    \"\"\"\n    X, y = create_lag_features(series, n_lags=n_lags)\n    \n    cv = WalkForwardCV(n_splits=n_splits, window_type='expanding', test_size=50)\n    model = Ridge(alpha=1.0)\n    \n    overall_results = []\n    regime_results = {'LOW': [], 'MEDIUM': [], 'HIGH': []}\n    \n    for fold_idx, (train_idx, test_idx) in enumerate(cv.split(X)):\n        # Get data\n        X_train, y_train = X[train_idx], y[train_idx]\n        X_test, y_test = X[test_idx], y[test_idx]\n        \n        # ‚ö†Ô∏è LAG OFFSET: Map from X indices back to original series indices\n        # X[0] corresponds to series[n_lags], so:\n        #   original_train_end = train_idx[-1] + n_lags\n        #   original_test_start = test_idx[0] + n_lags\n        original_train_end = train_idx[-1] + n_lags\n        \n        # Compute threshold from TRAINING data only (using original series)\n        # Changes array has length = series length - 1\n        train_changes = np.diff(series[:original_train_end + 1])\n        fold_threshold = np.percentile(np.abs(train_changes), 70)\n        \n        # Compute regimes for test period using training threshold\n        # Map test indices to original series\n        original_test_start = test_idx[0] + n_lags\n        original_test_end = test_idx[-1] + n_lags\n        \n        # Get changes for test period (aligned with predictions)\n        test_series_slice = series[original_test_start - 1:original_test_end + 1]\n        test_changes = np.diff(test_series_slice)\n        test_regimes = classify_moves(test_changes, fold_threshold)\n        \n        # Train and predict\n        model.fit(X_train, y_train)\n        preds = model.predict(X_test)\n        \n        # Overall MAE\n        overall_mae = mean_absolute_error(y_test, preds)\n        overall_results.append(overall_mae)\n        \n        # Stratified MAE (ensure lengths match)\n        n_test = len(y_test)\n        aligned_regimes = test_regimes[:n_test] if len(test_regimes) >= n_test else test_regimes\n        \n        for regime in ['LOW', 'MEDIUM', 'HIGH']:\n            if len(aligned_regimes) == n_test:\n                mask = aligned_regimes == regime\n                if np.sum(mask) >= 5:  # Need enough samples\n                    regime_mae = mean_absolute_error(y_test[mask], preds[mask])\n                    regime_results[regime].append(regime_mae)\n    \n    return {\n        'overall_mae': np.mean(overall_results),\n        'regime_maes': {k: np.mean(v) if v else np.nan for k, v in regime_results.items()}\n    }\n\n# Run evaluation\nprint(\"WALK-FORWARD CV WITH CORRECT THRESHOLDS\")\nprint(\"=\" * 60)\nprint(f\"\\nNote: Lag offset = {N_LAGS} (indices properly tracked)\")\n\nresults = evaluate_with_correct_thresholds(series_regime)\n\nprint(f\"\\nOverall MAE: {results['overall_mae']:.4f}\")\nprint(f\"\\nMAE by Regime:\")\nfor regime, mae in results['regime_maes'].items():\n    if not np.isnan(mae):\n        print(f\"  {regime}: {mae:.4f}\")\n\nprint(f\"\\n[T2] Thresholds computed from training data in each fold.\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": "---\n\n## Pitfall Section\n\n### Pitfall 1: Full-Series Percentiles\n\n```python\n# WRONG: Percentile from all data\nthreshold = np.percentile(np.abs(y), 70)\n\n# RIGHT: Percentile from training only\nthreshold = np.percentile(np.abs(y_train), 70)\n```\n\n### Pitfall 2: Wrong Volatility Basis\n\n```python\n# WRONG: Volatility from levels\nvol = series.rolling(13).std()  # BUG-005!\n\n# RIGHT: Volatility from changes\nchanges = series.diff()\nvol = changes.rolling(13).std()\n```\n\n### Pitfall 3: Ignoring Regime Stratification\n\n```python\n# WRONG: Only look at overall metrics\nprint(f\"Overall MAE: {mae}\")\n\n# RIGHT: Check performance by regime\nfor regime in ['LOW', 'MEDIUM', 'HIGH']:\n    mask = regimes == regime\n    print(f\"{regime} MAE: {mean_absolute_error(y[mask], preds[mask])}\")\n```\n\n### Pitfall 4: Thresholds Computed Outside CV\n\n```python\n# WRONG: Same threshold for all folds\nthreshold = np.percentile(np.abs(y), 70)\nfor train_idx, test_idx in cv.split(X):\n    regimes = classify(y[test_idx], threshold)  # Leakage!\n\n# RIGHT: Threshold per fold\nfor train_idx, test_idx in cv.split(X):\n    threshold = np.percentile(np.abs(y[train_idx]), 70)  # Training only\n    regimes = classify(y[test_idx], threshold)\n```\n\n### Pitfall 5: Lag Offset Misalignment ‚ö†Ô∏è\n\nWhen creating lag features, the first `n_lags` observations are dropped. This creates an **index offset** between the feature matrix and the original series:\n\n```python\n# DANGEROUS: Ignoring lag offset when mapping back to series\nn_lags = 5\nX, y = create_lag_features(series, n_lags=n_lags)  # X[0] = series[n_lags]!\n\nfor train_idx, test_idx in cv.split(X):\n    # WRONG: Using X indices directly on original series\n    train_changes = np.diff(series[:train_idx[-1]])  # Off by n_lags!\n    \n# CORRECT: Track the lag offset explicitly\nfor train_idx, test_idx in cv.split(X):\n    # Map X indices back to original series indices\n    original_train_end = train_idx[-1] + n_lags\n    original_test_start = test_idx[0] + n_lags\n    \n    # Now use correct indices for threshold computation\n    train_changes = np.diff(series[:original_train_end + 1])\n    threshold = np.percentile(np.abs(train_changes), 70)\n```\n\n**Key formula**: `original_series_index = feature_matrix_index + n_lags`\n\nThis is easy to overlook and causes subtle bugs where thresholds or regimes are computed on the wrong portion of data."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick reference: threshold computation rules\n",
    "print(\"THRESHOLD COMPUTATION RULES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "rules = [\n",
    "    (\"Move threshold\", \"70th percentile of |changes|\", \"Training data only\"),\n",
    "    (\"Volatility window\", \"13 periods (~quarterly)\", \"[T3] Assumption\"),\n",
    "    (\"Volatility basis\", \"'changes' not 'levels'\", \"BUG-005 prevention\"),\n",
    "    (\"Regime boundaries\", \"33rd/67th percentiles\", \"[T2] Training data only\"),\n",
    "    (\"Normalization\", \"mean/std from training\", \"Applied to test\"),\n",
    "]\n",
    "\n",
    "print(f\"\\n{'Threshold Type':<20} {'Value/Rule':<30} {'Source'}\")\n",
    "print(\"-\" * 70)\n",
    "for threshold_type, rule, source in rules:\n",
    "    print(f\"{threshold_type:<20} {rule:<30} {source}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Insights\n",
    "\n",
    "### 1. Thresholds Are Features [T2]\n",
    "Any threshold used for classification is effectively a feature. It must be computed from training data only.\n",
    "\n",
    "### 2. BUG-005: Use `basis='changes'` [T3]\n",
    "Volatility measures unpredictability of changes, not spread of levels. Steady drift is predictable.\n",
    "\n",
    "### 3. Stratification Reveals Hidden Failures\n",
    "A model may pass overall but fail in specific regimes. Always check stratified metrics.\n",
    "\n",
    "### 4. Threshold Computation Happens Per Fold\n",
    "In walk-forward CV, each fold computes its own thresholds from its training data.\n",
    "\n",
    "### 5. 70th Percentile is the Standard [T2]\n",
    "Per SPECIFICATION.md, moves above 70th percentile of |changes| are considered significant.\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- **08_validation_workflow.ipynb**: Complete HALT/WARN/PASS pipeline with `run_gates`\n",
    "- **12_regime_stratified_evaluation.ipynb**: Deep dive into stratified metrics (Tier 3)\n",
    "- **10_high_persistence_metrics.ipynb**: MC-SS and move-conditional evaluation\n",
    "\n",
    "---\n",
    "\n",
    "*\"Thresholds computed from future data aren't thresholds ‚Äî they're answers.\"*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}