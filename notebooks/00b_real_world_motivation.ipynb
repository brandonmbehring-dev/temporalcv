{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-World Motivation: Why Time-Series Validation Matters\n",
    "\n",
    "## Realistic Synthetic Examples of Time-Series Challenges\n",
    "\n",
    "---\n",
    "\n",
    "**Purpose**: See how real-world financial/economic data behaves and why standard ML approaches fail catastrophically.\n",
    "\n",
    "**Prerequisites**:\n",
    "- [00_time_series_fundamentals.ipynb](00_time_series_fundamentals.ipynb) — ACF intuition, why shuffling fails\n",
    "\n",
    "**What You'll Learn**:\n",
    "1. How interest rates, stock returns, and unemployment actually behave\n",
    "2. Why persistence makes prediction nearly impossible for some series\n",
    "3. When you can and cannot add value over naive forecasts\n",
    "4. How to diagnose your own data before building models\n",
    "\n",
    "**Time**: ~30 minutes\n",
    "\n",
    "---\n",
    "\n",
    "**All data in this notebook is SYNTHETIC** — generated to mimic real-world patterns without using proprietary data. The patterns and lessons, however, are based on decades of empirical research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from temporalcv.cv import WalkForwardCV\n",
    "from temporalcv import compute_mase, compute_naive_error\n",
    "\n",
    "np.random.seed(42)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "def compute_acf(series, max_lag=20):\n",
    "    \"\"\"Compute autocorrelation function.\"\"\"\n",
    "    n = len(series)\n",
    "    mean_s = np.mean(series)\n",
    "    var_s = np.var(series)\n",
    "    \n",
    "    acf = []\n",
    "    for lag in range(max_lag + 1):\n",
    "        if lag == 0:\n",
    "            acf.append(1.0)\n",
    "        else:\n",
    "            cov = np.mean((series[lag:] - mean_s) * (series[:-lag] - mean_s))\n",
    "            acf.append(cov / var_s)\n",
    "    return np.array(acf)\n",
    "\n",
    "print(\"Setup complete. Let's explore real-world patterns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 1: Treasury Rate Dynamics\n",
    "\n",
    "**What we're mimicking**: 10-Year Treasury Yield (weekly data)\n",
    "\n",
    "**Key characteristics**:\n",
    "- Extremely high persistence (φ ≈ 0.995)\n",
    "- Mean-reverting around a long-run equilibrium\n",
    "- Small weekly changes (typically ±0.10%)\n",
    "\n",
    "**The challenge**: If today's rate is 4.25%, tomorrow's rate is probably 4.24% or 4.26%. How do you beat \"predict no change\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_treasury_like(n_weeks=1040, phi=0.995, sigma=0.08, \n",
    "                           long_run_mean=2.5, seed=42):\n",
    "    \"\"\"\n",
    "    Generate synthetic Treasury-like rate series.\n",
    "    \n",
    "    Mimics 10-year Treasury yields:\n",
    "    - Very high persistence (φ ≈ 0.995)\n",
    "    - Mean-reverting around long-run mean\n",
    "    - Realistic weekly volatility (~8bp)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_weeks : int\n",
    "        Number of weekly observations (1040 ≈ 20 years)\n",
    "    phi : float\n",
    "        Autoregressive coefficient (persistence)\n",
    "    sigma : float\n",
    "        Innovation standard deviation\n",
    "    long_run_mean : float\n",
    "        Long-run equilibrium rate (%)\n",
    "    seed : int\n",
    "        Random seed for reproducibility\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    rates = np.zeros(n_weeks)\n",
    "    rates[0] = long_run_mean + rng.normal(0, sigma * 5)  # Start near equilibrium\n",
    "    \n",
    "    for t in range(1, n_weeks):\n",
    "        # Ornstein-Uhlenbeck: mean-reverting AR(1)\n",
    "        rates[t] = (phi * rates[t-1] + \n",
    "                    (1 - phi) * long_run_mean + \n",
    "                    sigma * rng.normal())\n",
    "    \n",
    "    return rates\n",
    "\n",
    "# Generate 20 years of weekly Treasury-like rates\n",
    "treasury_rates = generate_treasury_like(n_weeks=1040, phi=0.995, seed=42)\n",
    "\n",
    "# Compute ACF\n",
    "acf_treasury = compute_acf(treasury_rates, max_lag=52)  # 1 year of lags\n",
    "\n",
    "print(f\"Generated {len(treasury_rates)} weeks of synthetic Treasury rates\")\n",
    "print(f\"Mean rate: {np.mean(treasury_rates):.2f}%\")\n",
    "print(f\"Std dev: {np.std(treasury_rates):.2f}%\")\n",
    "print(f\"ACF(1): {acf_treasury[1]:.4f}\")\n",
    "print(f\"ACF(52) [1 year]: {acf_treasury[52]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Treasury dynamics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "\n",
    "# Top left: Time series\n",
    "ax = axes[0, 0]\n",
    "weeks = np.arange(len(treasury_rates))\n",
    "years = weeks / 52\n",
    "ax.plot(years, treasury_rates, 'b-', linewidth=0.8)\n",
    "ax.set_xlabel('Years')\n",
    "ax.set_ylabel('Rate (%)')\n",
    "ax.set_title('Synthetic 10-Year Treasury Yield (20 Years Weekly)', fontsize=11, fontweight='bold')\n",
    "ax.axhline(y=np.mean(treasury_rates), color='red', linestyle='--', alpha=0.5, label='Long-run mean')\n",
    "ax.legend()\n",
    "\n",
    "# Top right: ACF\n",
    "ax = axes[0, 1]\n",
    "lags = np.arange(len(acf_treasury))\n",
    "ax.bar(lags, acf_treasury, color='steelblue', alpha=0.7)\n",
    "ax.axhline(y=0.9, color='red', linestyle='--', label='High persistence threshold')\n",
    "ax.axhline(y=0, color='black', linewidth=0.5)\n",
    "ax.set_xlabel('Lag (weeks)')\n",
    "ax.set_ylabel('ACF')\n",
    "ax.set_title('Autocorrelation: Extremely Slow Decay', fontsize=11, fontweight='bold')\n",
    "ax.legend()\n",
    "\n",
    "# Bottom left: Weekly changes histogram\n",
    "ax = axes[1, 0]\n",
    "changes = np.diff(treasury_rates)\n",
    "ax.hist(changes, bins=50, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "ax.axvline(x=0, color='red', linestyle='--', linewidth=2, label='No change')\n",
    "ax.set_xlabel('Weekly Change (%)')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title(f'Weekly Changes: Mean={np.mean(changes):.4f}, Std={np.std(changes):.4f}', \n",
    "             fontsize=11, fontweight='bold')\n",
    "ax.legend()\n",
    "\n",
    "# Bottom right: Scatter of y[t] vs y[t-1]\n",
    "ax = axes[1, 1]\n",
    "ax.scatter(treasury_rates[:-1], treasury_rates[1:], alpha=0.3, s=10)\n",
    "min_val, max_val = treasury_rates.min(), treasury_rates.max()\n",
    "ax.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='y[t]=y[t-1]')\n",
    "ax.set_xlabel('Rate at week t-1 (%)')\n",
    "ax.set_ylabel('Rate at week t (%)')\n",
    "ax.set_title(f'Persistence: Tomorrow ≈ Today (corr={acf_treasury[1]:.3f})', \n",
    "             fontsize=11, fontweight='bold', color='red')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n★ Key Insight: With ACF(1)=0.995, the theoretical maximum improvement\")\n",
    "print(f\"   over persistence is only {(1-0.995)**2 * 100:.4f}%\")\n",
    "print(\"   → Beating 'predict no change' is nearly impossible!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 2: Stock Market Returns\n",
    "\n",
    "**What we're mimicking**: Daily S&P 500 returns\n",
    "\n",
    "**Key characteristics**:\n",
    "- Returns have VERY LOW persistence (ACF ≈ 0)\n",
    "- But volatility has HIGH persistence (volatility clustering)\n",
    "- Fat tails (extreme events more common than normal distribution)\n",
    "\n",
    "**The insight**: Predicting price LEVELS is easy (just predict yesterday's price). Predicting RETURNS is nearly impossible. But predicting VOLATILITY? That's doable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stock_returns(n_days=2520, vol_persistence=0.9, seed=42):\n",
    "    \"\"\"\n",
    "    Generate synthetic stock returns with GARCH-like volatility clustering.\n",
    "    \n",
    "    Key insight:\n",
    "    - Returns have LOW persistence (φ ≈ 0) — nearly unpredictable\n",
    "    - Volatility has HIGH persistence (φ ≈ 0.9) — clusters persist\n",
    "    - Fat tails from t-distribution\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_days : int\n",
    "        Number of daily observations (2520 ≈ 10 years)\n",
    "    vol_persistence : float\n",
    "        Persistence of volatility (GARCH beta parameter)\n",
    "    seed : int\n",
    "        Random seed\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    \n",
    "    # GARCH(1,1)-like volatility dynamics\n",
    "    vol = np.zeros(n_days)\n",
    "    vol[0] = 0.01  # 1% daily vol (about 16% annualized)\n",
    "    \n",
    "    # GARCH parameters: omega + alpha*r²[t-1] + beta*vol²[t-1]\n",
    "    omega = 0.00001  # Long-run variance contribution\n",
    "    alpha = 0.1       # Shock impact\n",
    "    beta = vol_persistence  # Volatility persistence\n",
    "    \n",
    "    returns = np.zeros(n_days)\n",
    "    \n",
    "    for t in range(1, n_days):\n",
    "        # Update volatility (GARCH dynamics)\n",
    "        vol[t] = np.sqrt(omega + alpha * returns[t-1]**2 + beta * vol[t-1]**2)\n",
    "        # Generate return with fat tails (t-distribution, df=5)\n",
    "        returns[t] = vol[t] * rng.standard_t(df=5)\n",
    "    \n",
    "    return returns, vol\n",
    "\n",
    "# Generate 10 years of daily returns\n",
    "stock_returns, stock_vol = generate_stock_returns(n_days=2520, vol_persistence=0.9, seed=42)\n",
    "\n",
    "# Compute prices (for illustration)\n",
    "prices = 100 * np.exp(np.cumsum(stock_returns))  # Start at 100\n",
    "\n",
    "# Compute ACFs\n",
    "acf_returns = compute_acf(stock_returns, max_lag=20)\n",
    "acf_abs_returns = compute_acf(np.abs(stock_returns), max_lag=20)\n",
    "\n",
    "print(f\"Generated {len(stock_returns)} days of synthetic stock returns\")\n",
    "print(f\"Mean daily return: {np.mean(stock_returns)*100:.3f}%\")\n",
    "print(f\"Daily volatility: {np.std(stock_returns)*100:.2f}%\")\n",
    "print(f\"Annualized volatility: {np.std(stock_returns)*np.sqrt(252)*100:.1f}%\")\n",
    "print(f\"\")\n",
    "print(f\"ACF(1) of returns: {acf_returns[1]:.4f}  ← VERY LOW (unpredictable)\")\n",
    "print(f\"ACF(1) of |returns|: {acf_abs_returns[1]:.4f}  ← HIGH (vol clusters)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize stock market dynamics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "\n",
    "days = np.arange(len(stock_returns))\n",
    "years = days / 252\n",
    "\n",
    "# Top left: Price (levels)\n",
    "ax = axes[0, 0]\n",
    "ax.plot(years, prices, 'b-', linewidth=0.8)\n",
    "ax.set_xlabel('Years')\n",
    "ax.set_ylabel('Price')\n",
    "ax.set_title('Price Levels: High Persistence (Easy to \"Predict\")', fontsize=11, fontweight='bold')\n",
    "\n",
    "# Top right: Returns\n",
    "ax = axes[0, 1]\n",
    "ax.plot(years, stock_returns * 100, 'b-', linewidth=0.5, alpha=0.7)\n",
    "ax.axhline(y=0, color='red', linestyle='--')\n",
    "ax.set_xlabel('Years')\n",
    "ax.set_ylabel('Daily Return (%)')\n",
    "ax.set_title('Returns: NO Persistence (Nearly Random)', fontsize=11, fontweight='bold', color='green')\n",
    "\n",
    "# Bottom left: Volatility\n",
    "ax = axes[1, 0]\n",
    "ax.plot(years, stock_vol * 100 * np.sqrt(252), 'orange', linewidth=1)\n",
    "ax.set_xlabel('Years')\n",
    "ax.set_ylabel('Annualized Volatility (%)')\n",
    "ax.set_title('Volatility: HIGH Persistence (Clusters)', fontsize=11, fontweight='bold', color='red')\n",
    "\n",
    "# Bottom right: ACF comparison\n",
    "ax = axes[1, 1]\n",
    "lags = np.arange(len(acf_returns))\n",
    "width = 0.35\n",
    "ax.bar(lags - width/2, acf_returns, width, label='Returns (unpredictable)', color='green', alpha=0.7)\n",
    "ax.bar(lags + width/2, acf_abs_returns, width, label='|Returns| (vol clustering)', color='orange', alpha=0.7)\n",
    "ax.axhline(y=0, color='black', linewidth=0.5)\n",
    "ax.axhline(y=1.96/np.sqrt(len(stock_returns)), color='gray', linestyle='--', alpha=0.5)\n",
    "ax.axhline(y=-1.96/np.sqrt(len(stock_returns)), color='gray', linestyle='--', alpha=0.5)\n",
    "ax.set_xlabel('Lag (days)')\n",
    "ax.set_ylabel('ACF')\n",
    "ax.set_title('ACF: Returns vs |Returns|', fontsize=11, fontweight='bold')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n★ Key Insight: Don't confuse levels with returns!\")\n",
    "print(\"   - Predicting PRICE levels is trivial (persistence is ~1.0)\")\n",
    "print(\"   - Predicting RETURNS is nearly impossible (ACF ≈ 0)\")\n",
    "print(\"   - Predicting VOLATILITY is feasible (ACF of |returns| ≈ 0.3)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 3: Unemployment Rate\n",
    "\n",
    "**What we're mimicking**: Monthly U.S. Unemployment Rate\n",
    "\n",
    "**Key characteristics**:\n",
    "- High persistence (φ ≈ 0.92)\n",
    "- Regime changes (recessions cause sudden jumps)\n",
    "- Asymmetric dynamics (fast up, slow down)\n",
    "\n",
    "**The challenge**: Persistence is high, AND there are structural breaks. The worst of both worlds for forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unemployment_like(n_months=240, phi=0.92, seed=42):\n",
    "    \"\"\"\n",
    "    Generate synthetic unemployment rate with regime changes.\n",
    "    \n",
    "    Features:\n",
    "    - High persistence within regimes (φ ≈ 0.92)\n",
    "    - Sudden jumps during recessions\n",
    "    - Slow decay after shocks (asymmetric)\n",
    "    - Floor at ~3% (full employment)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_months : int\n",
    "        Number of monthly observations (240 = 20 years)\n",
    "    phi : float\n",
    "        Autoregressive coefficient\n",
    "    seed : int\n",
    "        Random seed\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    \n",
    "    rates = np.zeros(n_months)\n",
    "    rates[0] = 5.0  # Start at 5% (normal level)\n",
    "    \n",
    "    # Recession timing (roughly every 7-10 years)\n",
    "    recession_months = [60, 140]  # Two recessions in 20 years\n",
    "    \n",
    "    for t in range(1, n_months):\n",
    "        # Check for recession shock\n",
    "        shock = 0\n",
    "        if t in recession_months:\n",
    "            shock = rng.uniform(2.5, 4.0)  # Jump 2.5-4 percentage points\n",
    "        \n",
    "        # Mean-reverting AR(1) with shock\n",
    "        long_run_mean = 4.5  # Natural rate\n",
    "        rates[t] = phi * rates[t-1] + (1-phi) * long_run_mean + 0.15 * rng.normal() + shock\n",
    "        \n",
    "        # Apply floor (can't go below ~3%)\n",
    "        rates[t] = max(rates[t], 3.0)\n",
    "    \n",
    "    return rates, recession_months\n",
    "\n",
    "# Generate 20 years of monthly unemployment\n",
    "unemployment, recessions = generate_unemployment_like(n_months=240, phi=0.92, seed=42)\n",
    "\n",
    "# Compute ACF\n",
    "acf_unemp = compute_acf(unemployment, max_lag=24)\n",
    "\n",
    "print(f\"Generated {len(unemployment)} months of synthetic unemployment data\")\n",
    "print(f\"Mean rate: {np.mean(unemployment):.1f}%\")\n",
    "print(f\"Min/Max: {np.min(unemployment):.1f}% / {np.max(unemployment):.1f}%\")\n",
    "print(f\"ACF(1): {acf_unemp[1]:.3f}\")\n",
    "print(f\"ACF(12) [1 year]: {acf_unemp[12]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize unemployment dynamics\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "months = np.arange(len(unemployment))\n",
    "years = months / 12\n",
    "\n",
    "# Left: Time series with recession markers\n",
    "ax = axes[0]\n",
    "ax.plot(years, unemployment, 'b-', linewidth=1.5)\n",
    "for rec in recessions:\n",
    "    ax.axvline(x=rec/12, color='red', linestyle='--', alpha=0.7, linewidth=2)\n",
    "ax.axhline(y=4.5, color='green', linestyle=':', alpha=0.7, label='Natural rate')\n",
    "ax.set_xlabel('Years')\n",
    "ax.set_ylabel('Unemployment Rate (%)')\n",
    "ax.set_title('Unemployment: High Persistence + Regime Changes', fontsize=11, fontweight='bold')\n",
    "ax.legend()\n",
    "\n",
    "# Annotate recessions\n",
    "ax.annotate('Recession\\nshock', xy=(recessions[0]/12, unemployment[recessions[0]]), \n",
    "            xytext=(recessions[0]/12 + 1, unemployment[recessions[0]] + 1),\n",
    "            arrowprops=dict(arrowstyle='->', color='red'),\n",
    "            fontsize=9, color='red')\n",
    "\n",
    "# Middle: ACF\n",
    "ax = axes[1]\n",
    "lags = np.arange(len(acf_unemp))\n",
    "ax.bar(lags, acf_unemp, color='steelblue', alpha=0.7)\n",
    "ax.axhline(y=0.9, color='red', linestyle='--', label='High persistence')\n",
    "ax.axhline(y=0, color='black', linewidth=0.5)\n",
    "ax.set_xlabel('Lag (months)')\n",
    "ax.set_ylabel('ACF')\n",
    "ax.set_title('ACF: Slow Decay (φ ≈ 0.92)', fontsize=11, fontweight='bold')\n",
    "ax.legend()\n",
    "\n",
    "# Right: Monthly changes histogram\n",
    "ax = axes[2]\n",
    "changes = np.diff(unemployment)\n",
    "ax.hist(changes, bins=30, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "ax.axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "\n",
    "# Mark recession jumps\n",
    "for rec in recessions:\n",
    "    if rec < len(changes):\n",
    "        ax.axvline(x=changes[rec-1], color='orange', linestyle='-', linewidth=2, alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Monthly Change (%)')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Changes: Mostly Small + Rare Large Jumps', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n★ Key Insight: High persistence + structural breaks = worst case\")\n",
    "print(\"   - Within regimes: persistence makes naive hard to beat\")\n",
    "print(\"   - Across regimes: breaks invalidate historical patterns\")\n",
    "print(\"   → Consider regime detection rather than point forecasting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 4: The Persistence Problem\n",
    "\n",
    "Now let's empirically verify what we've been saying: **high-persistence series are nearly impossible to beat with ML models**.\n",
    "\n",
    "We'll train a Ridge regression model on each series and compare to the naive forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lag_features(series, n_lags=5):\n",
    "    \"\"\"Create lag features for prediction.\"\"\"\n",
    "    n = len(series)\n",
    "    X = np.column_stack([\n",
    "        np.concatenate([[np.nan]*lag, series[:-lag]]) \n",
    "        for lag in range(1, n_lags + 1)\n",
    "    ])\n",
    "    valid = ~np.isnan(X).any(axis=1)\n",
    "    return X[valid], series[valid]\n",
    "\n",
    "def evaluate_vs_persistence(series, name, n_lags=5):\n",
    "    \"\"\"\n",
    "    Train a model and compare to persistence baseline.\n",
    "    Returns MASE and improvement percentage.\n",
    "    \"\"\"\n",
    "    X, y = create_lag_features(series, n_lags=n_lags)\n",
    "    \n",
    "    # Train-test split (80-20)\n",
    "    split_idx = int(len(X) * 0.8)\n",
    "    X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "    y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "    \n",
    "    # Train model\n",
    "    model = Ridge(alpha=1.0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    \n",
    "    # Persistence predictions (y[t-1])\n",
    "    persistence_preds = X_test[:, 0]\n",
    "    \n",
    "    # Metrics\n",
    "    model_mae = mean_absolute_error(y_test, preds)\n",
    "    persist_mae = mean_absolute_error(y_test, persistence_preds)\n",
    "    \n",
    "    # MASE (using training naive errors)\n",
    "    naive_errors = np.abs(np.diff(y_train))\n",
    "    naive_mae = np.mean(naive_errors)\n",
    "    mase = model_mae / naive_mae\n",
    "    \n",
    "    improvement = (persist_mae - model_mae) / persist_mae * 100\n",
    "    \n",
    "    # ACF(1)\n",
    "    acf1 = np.corrcoef(series[1:], series[:-1])[0, 1]\n",
    "    \n",
    "    return {\n",
    "        'name': name,\n",
    "        'acf1': acf1,\n",
    "        'model_mae': model_mae,\n",
    "        'persist_mae': persist_mae,\n",
    "        'mase': mase,\n",
    "        'improvement': improvement\n",
    "    }\n",
    "\n",
    "# Evaluate all three series\n",
    "results = [\n",
    "    evaluate_vs_persistence(treasury_rates, \"Treasury Rates\"),\n",
    "    evaluate_vs_persistence(unemployment, \"Unemployment\"),\n",
    "    evaluate_vs_persistence(stock_returns, \"Stock Returns\"),\n",
    "]\n",
    "\n",
    "print(\"THE PERSISTENCE PROBLEM: MODEL vs NAIVE FORECAST\")\n",
    "print(\"=\" * 75)\n",
    "print(f\"{'Series':<18} {'ACF(1)':<10} {'Model MAE':<12} {'Naive MAE':<12} {'MASE':<10} {'Improve'}\")\n",
    "print(\"-\" * 75)\n",
    "for r in results:\n",
    "    verdict = '✓' if r['mase'] < 1 else '✗'\n",
    "    print(f\"{r['name']:<18} {r['acf1']:<10.3f} {r['model_mae']:<12.4f} {r['persist_mae']:<12.4f} \"\n",
    "          f\"{r['mase']:<10.3f} {r['improvement']:>+.1f}% {verdict}\")\n",
    "print(\"-\" * 75)\n",
    "print(\"\\nMASE < 1 = Model beats naive | MASE ≥ 1 = No skill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the persistence-difficulty relationship\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot each series\n",
    "acfs = [r['acf1'] for r in results]\n",
    "mases = [r['mase'] for r in results]\n",
    "names = [r['name'] for r in results]\n",
    "colors = ['red' if m >= 1 else 'green' for m in mases]\n",
    "\n",
    "ax.scatter(acfs, mases, c=colors, s=200, alpha=0.7, edgecolors='black', linewidth=2)\n",
    "\n",
    "# Add labels\n",
    "for acf, mase, name in zip(acfs, mases, names):\n",
    "    ax.annotate(name, (acf, mase), textcoords=\"offset points\", \n",
    "                xytext=(10, 5), fontsize=11, fontweight='bold')\n",
    "\n",
    "# Reference lines\n",
    "ax.axhline(y=1, color='black', linestyle='--', linewidth=2, label='MASE=1 (no skill)')\n",
    "ax.axvline(x=0.9, color='red', linestyle=':', alpha=0.7, label='High persistence threshold')\n",
    "\n",
    "# Theoretical curve (approximate)\n",
    "phi_range = np.linspace(0, 0.99, 100)\n",
    "# For very high phi, MASE → 1\n",
    "theoretical_mase = 1 - 0.5 * (1 - phi_range**2)\n",
    "ax.plot(phi_range, theoretical_mase, 'gray', linestyle='-', alpha=0.5, \n",
    "        label='Approximate lower bound')\n",
    "\n",
    "ax.set_xlabel('ACF(1) — Persistence Level', fontsize=12)\n",
    "ax.set_ylabel('MASE — Model Performance', fontsize=12)\n",
    "ax.set_title('The Persistence Problem: Higher ACF → Harder to Beat Naive', \n",
    "             fontsize=13, fontweight='bold')\n",
    "ax.legend(loc='upper left')\n",
    "ax.set_xlim(-0.1, 1.05)\n",
    "ax.set_ylim(0, 1.5)\n",
    "\n",
    "# Add regions\n",
    "ax.fill_between([0.9, 1.05], 0, 1.5, color='red', alpha=0.1)\n",
    "ax.fill_between([-0.1, 0.7], 0, 1.5, color='green', alpha=0.1)\n",
    "\n",
    "ax.annotate('Hard Zone\\n(ACF > 0.9)', xy=(0.95, 0.2), fontsize=10, color='red', \n",
    "            ha='center', fontweight='bold')\n",
    "ax.annotate('Achievable Zone\\n(ACF < 0.7)', xy=(0.3, 0.2), fontsize=10, color='green', \n",
    "            ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 5: Decision Framework\n",
    "\n",
    "### Before Building a Model, Ask These Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagnose_series(series, name=\"Your Series\"):\n",
    "    \"\"\"\n",
    "    Quick diagnostic for any time series.\n",
    "    \n",
    "    Returns ACF(1), persistence classification, and guidance.\n",
    "    Use this BEFORE building models!\n",
    "    \"\"\"\n",
    "    n = len(series)\n",
    "    acf1 = np.corrcoef(series[1:], series[:-1])[0, 1]\n",
    "    \n",
    "    # Persistence baseline MAE\n",
    "    persist_errors = np.abs(series[1:] - series[:-1])\n",
    "    persist_mae = np.mean(persist_errors)\n",
    "    \n",
    "    # Theoretical maximum improvement [T1]\n",
    "    max_improvement = (1 - acf1**2) * 100 if acf1 > 0 else 100\n",
    "    \n",
    "    print(f\"DIAGNOSTIC: {name}\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Observations:      {n}\")\n",
    "    print(f\"ACF(1):            {acf1:.4f}\")\n",
    "    print(f\"Persistence MAE:   {persist_mae:.6f}\")\n",
    "    print(f\"\")\n",
    "    \n",
    "    # Classification and guidance\n",
    "    if acf1 > 0.95:\n",
    "        level = \"EXTREMELY HIGH\"\n",
    "        color = \"\\033[91m\"  # Red\n",
    "        guidance = [\n",
    "            \"Beating persistence is nearly IMPOSSIBLE.\",\n",
    "            \"Consider: Do you even need to predict?\",\n",
    "            \"Alternative tasks: Direction, regimes, uncertainty quantification\",\n",
    "            f\"Theoretical max improvement: <{max_improvement:.2f}%\"\n",
    "        ]\n",
    "    elif acf1 > 0.90:\n",
    "        level = \"VERY HIGH\"\n",
    "        color = \"\\033[93m\"  # Yellow\n",
    "        guidance = [\n",
    "            \"Beating persistence is VERY DIFFICULT.\",\n",
    "            \"Use MASE as primary metric (not MAE/RMSE).\",\n",
    "            \"Consider move-conditional metrics.\",\n",
    "            f\"Theoretical max improvement: <{max_improvement:.1f}%\"\n",
    "        ]\n",
    "    elif acf1 > 0.70:\n",
    "        level = \"MODERATE\"\n",
    "        color = \"\\033[93m\"  # Yellow\n",
    "        guidance = [\n",
    "            \"Improvement is POSSIBLE but limited.\",\n",
    "            \"Always report MASE alongside MAE.\",\n",
    "            \"Expect small but meaningful gains.\",\n",
    "            f\"Theoretical max improvement: ~{max_improvement:.0f}%\"\n",
    "        ]\n",
    "    else:\n",
    "        level = \"LOW\"\n",
    "        color = \"\\033[92m\"  # Green\n",
    "        guidance = [\n",
    "            \"Standard ML can add SIGNIFICANT value.\",\n",
    "            \"MAE/RMSE are meaningful metrics.\",\n",
    "            \"Good candidate for model development.\",\n",
    "            f\"Theoretical max improvement: ~{max_improvement:.0f}%\"\n",
    "        ]\n",
    "    \n",
    "    print(f\"Persistence Level: {level}\")\n",
    "    print(f\"\")\n",
    "    print(\"Guidance:\")\n",
    "    for g in guidance:\n",
    "        print(f\"  → {g}\")\n",
    "    \n",
    "    return {'acf1': acf1, 'persist_mae': persist_mae, 'level': level}\n",
    "\n",
    "# Demonstrate on each series\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "diagnose_series(treasury_rates, \"Synthetic Treasury Rates\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "diagnose_series(stock_returns, \"Synthetic Stock Returns\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "diagnose_series(unemployment, \"Synthetic Unemployment Rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Flowchart\n",
    "\n",
    "```\n",
    "Your data → Compute ACF(1)\n",
    "    │\n",
    "    ├─ ACF(1) > 0.95 ───────────────────────────────────────────────────┐\n",
    "    │   │                                                                │\n",
    "    │   └─ DON'T predict levels                                          │\n",
    "    │      Consider instead:                                             │\n",
    "    │      • Direction prediction (up/down)                              │\n",
    "    │      • Regime detection (normal vs stressed)                       │\n",
    "    │      • Uncertainty quantification (intervals)                      │\n",
    "    │                                                                    │\n",
    "    ├─ 0.7 < ACF(1) < 0.95 ──────────────────────────────────────────┐  │\n",
    "    │   │                                                             │  │\n",
    "    │   └─ Use MASE as primary metric                                 │  │\n",
    "    │      Expect small improvements (2-10%)                          │  │\n",
    "    │      Consider move-conditional metrics                          │  │\n",
    "    │                                                                 │  │\n",
    "    └─ ACF(1) < 0.7 ─────────────────────────────────────────────────┐│  │\n",
    "        │                                                            ││  │\n",
    "        └─ Standard ML can add value                                 ││  │\n",
    "           MAE/RMSE are meaningful                                   ││  │\n",
    "           Good candidate for modeling                               ││  │\n",
    "                                                                     ││  │\n",
    "                                                                     ▼▼  ▼\n",
    "                                                              Run validation\n",
    "                                                              with temporalcv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "### 1. Treasury/Interest Rates (ACF ≈ 0.99)\n",
    "- Persistence is nearly unbeatable\n",
    "- \"Tomorrow = today\" is an excellent forecast\n",
    "- Focus on direction or uncertainty, not point forecasts\n",
    "\n",
    "### 2. Stock Returns vs Levels\n",
    "- **Levels** have high persistence (easy to \"predict\" trivially)\n",
    "- **Returns** have near-zero persistence (nearly unpredictable)\n",
    "- **Volatility** has moderate persistence (can be modeled)\n",
    "- Don't confuse predicting prices with predicting returns!\n",
    "\n",
    "### 3. Unemployment and Economic Indicators\n",
    "- High persistence + regime changes = very hard\n",
    "- Focus on regime detection rather than point forecasting\n",
    "- Be skeptical of models that \"beat\" persistence by large margins\n",
    "\n",
    "### 4. The Rule: Check ACF(1) FIRST\n",
    "\n",
    "| ACF(1) | What to Expect |\n",
    "|--------|----------------|\n",
    "| > 0.95 | Don't predict levels |\n",
    "| 0.9-0.95 | MASE ≈ 1.0 is normal |\n",
    "| 0.7-0.9 | Small gains possible |\n",
    "| < 0.7 | Standard ML works |\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Now that you understand WHY time-series validation is critical:\n",
    "\n",
    "1. **[01_why_temporal_cv.ipynb](01_why_temporal_cv.ipynb)**: Learn to validate correctly with WalkForwardCV\n",
    "2. **[Feature Engineering Safety Guide](../docs/tutorials/feature_engineering_safety.md)**: Avoid common feature leakage traps\n",
    "3. **[Metric Selection Guide](../docs/tutorials/metric_selection.md)**: Choose the right metric for your problem\n",
    "\n",
    "---\n",
    "\n",
    "*\"Always check ACF(1) before building models. If it's above 0.95, ask yourself: is prediction even the right task?\"*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
