{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 11: Conformal Prediction\n\n**Distribution-Free Prediction Intervals with Coverage Guarantees**\n\n---\n\n## ðŸš¨ If You Know sklearn But Not Uncertainty Quantification, Read This First\n\n**What you already know (from standard ML)**:\n- Point predictions: \"The model predicts 5.23\"\n- Confidence intervals: \"We're 95% confident the value is in [5.0, 5.5]\"\n- Gaussian assumptions underlie most interval methods\n\n**What's different with conformal prediction**:\n\n| Traditional Intervals | Conformal Prediction |\n|----------------------|---------------------|\n| Assumes Gaussian errors | **Distribution-free** |\n| Asymptotic guarantees (need large n) | **Finite-sample** guarantees |\n| Model-specific formulas | Works with **any model** |\n| Hard to calibrate | Calibration is automatic |\n\n**The key insight**:\n\nConformal prediction doesn't assume anything about error distribution. It uses a **calibration set** to learn how wrong your model typically is, then constructs intervals that cover the true value with guaranteed probability.\n\n```python\n# Traditional (assumes normality):\ninterval = prediction Â± 1.96 * estimated_std\n\n# Conformal (no assumptions):\ninterval = prediction Â± learned_quantile_from_calibration_data\n```\n\n**Coverage guarantee**: For any distribution, any model:\n```\nP(Y âˆˆ predicted_interval) â‰¥ 1 - Î±\n```\n\nThis holds for **finite samples**, not just asymptotically!\n\n---\n\n## What You'll Learn\n\n1. **Why point predictions aren't enough** â€” Uncertainty quantification for decision-making\n2. **Split conformal prediction** â€” Finite-sample coverage guarantees [T1]\n3. **Adaptive conformal** â€” Handling distribution shift [T1]\n\n**Prerequisites**: Notebooks 01-04 (Foundation tier)\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Problem: Point Predictions Without Uncertainty\n",
    "\n",
    "Consider this forecast:\n",
    "\n",
    "```\n",
    "Model prediction: 5.23\n",
    "```\n",
    "\n",
    "**Questions we can't answer:**\n",
    "- How confident are we in this prediction?\n",
    "- What's the range of likely outcomes?\n",
    "- Should we make a high-stakes decision based on this?\n",
    "\n",
    "**The solution**: Prediction intervals with coverage guarantees.\n",
    "\n",
    "```\n",
    "90% prediction interval: [4.87, 5.59]\n",
    "```\n",
    "\n",
    "Now we know: \"We expect 90% of actuals to fall within this range.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from temporalcv.conformal import (\n",
    "    SplitConformalPredictor,\n",
    "    AdaptiveConformalPredictor,\n",
    "    walk_forward_conformal,\n",
    "    evaluate_interval_quality,\n",
    "    PredictionInterval,\n",
    ")\n",
    "\n",
    "np.random.seed(42)\n",
    "print(\"temporalcv conformal prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data\n",
    "def generate_ar1(n: int, phi: float = 0.9, sigma: float = 0.1) -> np.ndarray:\n",
    "    \"\"\"Generate AR(1) process: y[t] = phi * y[t-1] + epsilon[t]\"\"\"\n",
    "    y = np.zeros(n)\n",
    "    y[0] = np.random.normal(0, sigma)\n",
    "    for t in range(1, n):\n",
    "        y[t] = phi * y[t - 1] + np.random.normal(0, sigma)\n",
    "    return y\n",
    "\n",
    "# Create dataset\n",
    "n = 500\n",
    "y = generate_ar1(n, phi=0.9)\n",
    "\n",
    "# Create features and split\n",
    "X = np.column_stack([y[:-2], y[1:-1]])\n",
    "y_target = y[2:]\n",
    "\n",
    "train_size = int(len(y_target) * 0.7)\n",
    "X_train, y_train = X[:train_size], y_target[:train_size]\n",
    "X_test, y_test = X[train_size:], y_target[train_size:]\n",
    "\n",
    "# Train model\n",
    "model = Ridge(alpha=1.0)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "print(f\"Train: {len(X_train)}, Test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Split Conformal Prediction [T1]\n",
    "\n",
    "**Key idea**: Use a calibration set to learn prediction uncertainty.\n",
    "\n",
    "**Coverage guarantee**: For any distribution, any model:\n",
    "```\n",
    "P(Y âˆˆ Äˆ) â‰¥ 1 - Î±\n",
    "```\n",
    "\n",
    "This is a **finite-sample** guarantee â€” it holds for any sample size!\n",
    "\n",
    "**Citation**: Romano et al. (2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split test set: 30% calibration, 70% holdout\n",
    "cal_size = int(len(X_test) * 0.3)\n",
    "X_cal, y_cal = X_test[:cal_size], y_test[:cal_size]\n",
    "X_holdout, y_holdout = X_test[cal_size:], y_test[cal_size:]\n",
    "\n",
    "# Get predictions for each split\n",
    "cal_preds = model.predict(X_cal)\n",
    "holdout_preds = model.predict(X_holdout)\n",
    "\n",
    "print(f\"Calibration: {len(X_cal)}, Holdout: {len(X_holdout)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and calibrate conformal predictor\n",
    "conformal = SplitConformalPredictor(alpha=0.10)  # 90% intervals\n",
    "conformal.calibrate(cal_preds, y_cal)\n",
    "\n",
    "print(f\"Calibrated quantile: {conformal.quantile_:.4f}\")\n",
    "print(f\"This is the width of intervals (Â± from prediction)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate prediction intervals\n",
    "intervals = conformal.predict_interval(holdout_preds)\n",
    "\n",
    "print(f\"\\nPrediction Intervals (first 5):\")\n",
    "for i in range(5):\n",
    "    print(f\"  Point: {intervals.point[i]:.3f}, Interval: [{intervals.lower[i]:.3f}, {intervals.upper[i]:.3f}]\")\n",
    "\n",
    "print(f\"\\nMean interval width: {intervals.mean_width:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check coverage on HOLDOUT data (not calibration!)\n",
    "coverage = intervals.coverage(y_holdout)\n",
    "\n",
    "print(f\"\\nCoverage on holdout: {coverage:.1%}\")\n",
    "print(f\"Target coverage: {intervals.confidence:.1%}\")\n",
    "print(f\"Gap: {(coverage - intervals.confidence)*100:.1f}pp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantile Formula [T1]\n",
    "\n",
    "The conformal quantile is computed as:\n",
    "\n",
    "```\n",
    "q = ceil((n + 1)(1 - Î±)) / n\n",
    "```\n",
    "\n",
    "This ensures finite-sample validity. For n=45 and Î±=0.10:\n",
    "- q = ceil(46 Ã— 0.9) / 45 = ceil(41.4) / 45 = 42/45 = 0.933"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Walk-Forward Conformal [T2]\n",
    "\n",
    "For time series, `walk_forward_conformal` handles the split automatically:\n",
    "\n",
    "1. First 30% â†’ calibration\n",
    "2. Remaining 70% â†’ holdout\n",
    "3. Coverage evaluated **only on holdout**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Walk-forward conformal (recommended for time series)\n",
    "intervals, quality = walk_forward_conformal(\n",
    "    predictions=predictions,  # All test predictions\n",
    "    actuals=y_test,           # All test actuals\n",
    "    calibration_fraction=0.3,\n",
    "    alpha=0.10,               # 90% intervals\n",
    ")\n",
    "\n",
    "print(\"Walk-Forward Conformal Results:\")\n",
    "print(f\"  Coverage: {quality['coverage']:.1%}\")\n",
    "print(f\"  Target:   {quality['target_coverage']:.1%}\")\n",
    "print(f\"  Gap:      {quality['coverage_gap']*100:.1f}pp\")\n",
    "print(f\"\\n  Mean width:      {quality['mean_width']:.4f}\")\n",
    "print(f\"  Interval score:  {quality['interval_score']:.4f}\")\n",
    "print(f\"  Quantile:        {quality['quantile']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interval Score (Proper Scoring Rule)\n",
    "\n",
    "The interval score penalizes both:\n",
    "- **Wide intervals** (lack of precision)\n",
    "- **Miscoverage** (lack of calibration)\n",
    "\n",
    "```\n",
    "Score = width + (2/Î±) Ã— penalty_for_miscoverage\n",
    "```\n",
    "\n",
    "Lower is better. This prevents gaming coverage with overly wide intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Adaptive Conformal [T1]\n",
    "\n",
    "For **non-stationary** data (distribution shift), adaptive conformal adjusts online:\n",
    "\n",
    "- If covered â†’ decrease quantile (tighten intervals)\n",
    "- If not covered â†’ increase quantile (widen intervals)\n",
    "\n",
    "**Citation**: Gibbs & CandÃ¨s (2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate distribution shift\n",
    "# First half: low volatility\n",
    "y_shift1 = generate_ar1(100, phi=0.9, sigma=0.05)\n",
    "# Second half: high volatility\n",
    "y_shift2 = generate_ar1(100, phi=0.9, sigma=0.3)\n",
    "y_shift2 = y_shift2 + y_shift1[-1]  # Continue from where we left off\n",
    "\n",
    "y_shifted = np.concatenate([y_shift1, y_shift2])\n",
    "\n",
    "# Create features\n",
    "X_shifted = np.column_stack([y_shifted[:-2], y_shifted[1:-1]])\n",
    "y_shifted_target = y_shifted[2:]\n",
    "\n",
    "# Train on first portion\n",
    "model_shift = Ridge()\n",
    "model_shift.fit(X_shifted[:80], y_shifted_target[:80])\n",
    "preds_shifted = model_shift.predict(X_shifted[80:])\n",
    "actuals_shifted = y_shifted_target[80:]\n",
    "\n",
    "print(f\"Shift occurs around index 100\")\n",
    "print(f\"Testing on indices 80-198\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize adaptive conformal\n",
    "adaptive = AdaptiveConformalPredictor(alpha=0.10, gamma=0.1)\n",
    "\n",
    "# Initialize with first 20 points\n",
    "adaptive.initialize(preds_shifted[:20], actuals_shifted[:20])\n",
    "\n",
    "print(f\"Initial quantile: {adaptive._current_quantile:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Online updates\n",
    "coverages = []\n",
    "quantiles = []\n",
    "\n",
    "for i in range(20, len(preds_shifted)):\n",
    "    pred = preds_shifted[i]\n",
    "    actual = actuals_shifted[i]\n",
    "    \n",
    "    # Get interval\n",
    "    lower, upper = adaptive.predict_interval(pred)\n",
    "    covered = lower <= actual <= upper\n",
    "    coverages.append(covered)\n",
    "    \n",
    "    # Update quantile based on coverage\n",
    "    adaptive.update(pred, actual)\n",
    "    quantiles.append(adaptive._current_quantile)\n",
    "\n",
    "# Check coverage in different periods\n",
    "first_half = coverages[:len(coverages)//2]\n",
    "second_half = coverages[len(coverages)//2:]\n",
    "\n",
    "print(f\"Coverage first half (low vol):  {np.mean(first_half):.1%}\")\n",
    "print(f\"Coverage second half (high vol): {np.mean(second_half):.1%}\")\n",
    "print(f\"Overall coverage: {np.mean(coverages):.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show quantile adaptation\n",
    "print(f\"\\nQuantile evolution:\")\n",
    "print(f\"  Start:  {quantiles[0]:.4f}\")\n",
    "print(f\"  Middle: {quantiles[len(quantiles)//2]:.4f}\")\n",
    "print(f\"  End:    {quantiles[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key insight**: Adaptive conformal widened intervals after the distribution shift to maintain coverage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Interval Quality Metrics\n",
    "\n",
    "Beyond coverage, we want to evaluate:\n",
    "\n",
    "| Metric | What It Measures |\n",
    "|--------|------------------|\n",
    "| Coverage | Fraction of actuals within intervals |\n",
    "| Mean width | Average interval size (smaller = more precise) |\n",
    "| Interval score | Proper scoring rule (penalizes both width and miscoverage) |\n",
    "| Conditional coverage | Coverage by prediction magnitude |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate interval quality\n",
    "quality_metrics = evaluate_interval_quality(intervals, y_test[cal_size:])\n",
    "\n",
    "print(\"Interval Quality Metrics:\")\n",
    "for key, value in quality_metrics.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {key}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Pitfall Section: Common Mistakes\n",
    "\n",
    "### Pitfall 1: Coverage on Calibration Data\n",
    "\n",
    "```python\n",
    "# WRONG: Evaluate coverage on calibration data\n",
    "conformal.calibrate(cal_preds, cal_actuals)\n",
    "intervals = conformal.predict_interval(cal_preds)  # Same data!\n",
    "coverage = intervals.coverage(cal_actuals)  # Inflated!\n",
    "\n",
    "# RIGHT: Evaluate on fresh holdout data\n",
    "conformal.calibrate(cal_preds, cal_actuals)\n",
    "intervals = conformal.predict_interval(holdout_preds)  # Different data\n",
    "coverage = intervals.coverage(holdout_actuals)  # Valid\n",
    "```\n",
    "\n",
    "**Why it matters**: Calibration data is by definition close to predictions. Coverage on calibration is inflated.\n",
    "\n",
    "---\n",
    "\n",
    "### Pitfall 2: Static Conformal on Shifting Data\n",
    "\n",
    "```python\n",
    "# WRONG: Use static conformal when data distribution shifts\n",
    "conformal = SplitConformalPredictor(alpha=0.10)\n",
    "conformal.calibrate(old_data)  # Won't adapt!\n",
    "\n",
    "# RIGHT: Use adaptive conformal for distribution shift\n",
    "adaptive = AdaptiveConformalPredictor(alpha=0.10, gamma=0.1)\n",
    "# Updates online to maintain coverage\n",
    "```\n",
    "\n",
    "**Why it matters**: Static quantiles fail when volatility changes.\n",
    "\n",
    "---\n",
    "\n",
    "### Pitfall 3: Gaming Coverage with Wide Intervals\n",
    "\n",
    "```python\n",
    "# WRONG: Report only coverage (can be gamed)\n",
    "print(f\"Coverage: {coverage:.1%}\")  # Could be 99% with Â±infinity intervals\n",
    "\n",
    "# RIGHT: Report interval score (proper scoring rule)\n",
    "quality = evaluate_interval_quality(intervals, actuals)\n",
    "print(f\"Interval score: {quality['interval_score']:.4f}\")\n",
    "```\n",
    "\n",
    "**Why it matters**: Interval score penalizes both width and miscoverage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Insights\n",
    "\n",
    "```\n",
    "â˜… Insight â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "1. Conformal prediction gives distribution-free guarantees [T1]\n",
    "   - P(Y âˆˆ Äˆ) â‰¥ 1 - Î± holds for any distribution\n",
    "   - Finite-sample valid (not just asymptotic)\n",
    "\n",
    "2. Walk-forward conformal is time-series aware\n",
    "   - Calibration on first 30%, holdout on rest\n",
    "   - Never evaluate coverage on calibration data!\n",
    "\n",
    "3. Adaptive conformal handles distribution shift [T1]\n",
    "   - Online updates to maintain coverage\n",
    "   - gamma controls adaptation speed [T3]\n",
    "\n",
    "4. Use interval score, not just coverage\n",
    "   - Proper scoring rule prevents gaming\n",
    "   - Penalizes both width and miscoverage\n",
    "\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "| Notebook | Topic |\n",
    "|----------|-------|\n",
    "| **12** | Regime-stratified evaluation (capstone) |\n",
    "\n",
    "---\n",
    "\n",
    "**You've learned**: How to construct prediction intervals with coverage guarantees using conformal prediction, and how to adapt to distribution shift with online updates."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}