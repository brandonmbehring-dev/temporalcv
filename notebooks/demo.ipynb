{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TemporalCV: Validation Gates for Time-Series ML\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/brandonmbehring-dev/temporalcv/blob/main/notebooks/demo.ipynb)\n",
    "\n",
    "This notebook demonstrates temporalcv's key features:\n",
    "\n",
    "1. **Leakage Detection**: Shuffled target test catches data leakage\n",
    "2. **Walk-Forward CV**: Gap enforcement for h-step forecasting\n",
    "3. **Statistical Tests**: DM test for model comparison\n",
    "4. **Conformal Prediction**: Distribution-free prediction intervals\n",
    "\n",
    "---\n",
    "\n",
    "**Key Insight**: 80% of timeseries models I've seen have subtle leakage bugs. The shuffled target test is the definitive detector — if your model beats a permuted baseline, it's learning from temporal position alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install temporalcv (uncomment for Colab)\n",
    "# !pip install temporalcv scikit-learn matplotlib -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from temporalcv.cv import WalkForwardCV\n",
    "from temporalcv.gates import (\n",
    "    gate_shuffled_target,\n",
    "    gate_temporal_boundary,\n",
    "    run_gates,\n",
    ")\n",
    "from temporalcv.conformal import (\n",
    "    AdaptiveConformalPredictor,\n",
    "    walk_forward_conformal,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "print(\"✓ All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation\n",
    "\n",
    "We generate AR(1) data mimicking Treasury rates — high persistence (φ ≈ 0.95) where persistence baseline is very hard to beat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ar1_data(n=500, phi=0.9, sigma=1.0, seed=42):\n",
    "    \"\"\"Generate AR(1) process.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    y = np.zeros(n)\n",
    "    y[0] = rng.normal(0, sigma / np.sqrt(1 - phi**2))\n",
    "    for t in range(1, n):\n",
    "        y[t] = phi * y[t - 1] + sigma * rng.normal()\n",
    "    return y\n",
    "\n",
    "def create_features(series, n_lags=5):\n",
    "    \"\"\"Create lagged features.\"\"\"\n",
    "    n = len(series)\n",
    "    features = []\n",
    "    for lag in range(1, n_lags + 1):\n",
    "        lagged = np.full(n, np.nan)\n",
    "        lagged[lag:] = series[:-lag]\n",
    "        features.append(lagged)\n",
    "    X = np.column_stack(features)\n",
    "    y = series.copy()\n",
    "    valid = ~np.isnan(X).any(axis=1)\n",
    "    return X[valid], y[valid]\n",
    "\n",
    "# Generate data\n",
    "series = generate_ar1_data(n=500, phi=0.9)\n",
    "X, y = create_features(series, n_lags=5)\n",
    "\n",
    "# Calculate ACF(1)\n",
    "acf1 = np.corrcoef(series[1:], series[:-1])[0, 1]\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].plot(series, linewidth=0.8)\n",
    "axes[0].set_title(f'AR(1) Process (ACF(1) = {acf1:.3f})')\n",
    "axes[0].set_xlabel('Time')\n",
    "axes[0].set_ylabel('Value')\n",
    "\n",
    "# ACF plot\n",
    "lags = range(1, 21)\n",
    "acf_values = [np.corrcoef(series[lag:], series[:-lag])[0, 1] for lag in lags]\n",
    "axes[1].bar(lags, acf_values, color='steelblue', alpha=0.7)\n",
    "axes[1].axhline(y=0.05, color='r', linestyle='--', label='Significance bound')\n",
    "axes[1].axhline(y=-0.05, color='r', linestyle='--')\n",
    "axes[1].set_title('Autocorrelation Function')\n",
    "axes[1].set_xlabel('Lag')\n",
    "axes[1].set_ylabel('ACF')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Data shape: X={X.shape}, y={y.shape}\")\n",
    "print(f\"ACF(1) = {acf1:.3f} — HIGH persistence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Leakage Detection with Shuffled Target Test\n",
    "\n",
    "The **shuffled target test** is the definitive leakage detector:\n",
    "- Train model on real targets → get MAE_real\n",
    "- Train model on shuffled (permuted) targets → get MAE_shuffled\n",
    "- If MAE_real << MAE_shuffled, features encode target information\n",
    "\n",
    "**Why this works**: Shuffling breaks temporal ordering. If features contain lookahead info, the model will still perform well on shuffled targets (because it's reading future values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with CLEAN features (only lag values)\n",
    "model = Ridge(alpha=1.0)\n",
    "\n",
    "result = gate_shuffled_target(\n",
    "    model=model,\n",
    "    X=X,\n",
    "    y=y,\n",
    "    n_shuffles=10,\n",
    "    threshold=0.95,  # HALT if improvement > 95%\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "print(\"CLEAN FEATURES (lag values only)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Status: {result.status.value}\")\n",
    "print(f\"MAE (real): {result.details['mae_real']:.4f}\")\n",
    "print(f\"MAE (shuffled): {result.details['mae_shuffled_avg']:.4f}\")\n",
    "print(f\"Improvement: {result.metric_value:.1%}\")\n",
    "print()\n",
    "print(\"Interpretation: Lag features genuinely predict AR(1), so\")\n",
    "print(\"some improvement over shuffled is expected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LEAKY features (include future info)\n",
    "def create_leaky_features(series, n_lags=5):\n",
    "    \"\"\"Features WITH leakage — intentionally buggy.\"\"\"\n",
    "    n = len(series)\n",
    "    features = []\n",
    "    \n",
    "    # Normal lags\n",
    "    for lag in range(1, n_lags + 1):\n",
    "        lagged = np.full(n, np.nan)\n",
    "        lagged[lag:] = series[:-lag]\n",
    "        features.append(lagged)\n",
    "    \n",
    "    # BUG: Centered rolling mean (includes future!)\n",
    "    smoothed = np.full(n, np.nan)\n",
    "    window = 3\n",
    "    for t in range(window, n - window):\n",
    "        smoothed[t] = np.mean(series[t - window : t + window + 1])  # FUTURE!\n",
    "    features.append(smoothed)\n",
    "    \n",
    "    X = np.column_stack(features)\n",
    "    y = series.copy()\n",
    "    valid = ~np.isnan(X).any(axis=1)\n",
    "    return X[valid], y[valid]\n",
    "\n",
    "X_leaky, y_leaky = create_leaky_features(series)\n",
    "\n",
    "result_leaky = gate_shuffled_target(\n",
    "    model=Ridge(alpha=1.0),\n",
    "    X=X_leaky,\n",
    "    y=y_leaky,\n",
    "    n_shuffles=10,\n",
    "    threshold=0.95,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "print(\"LEAKY FEATURES (includes future)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Status: {result_leaky.status.value}\")\n",
    "print(f\"MAE (real): {result_leaky.details['mae_real']:.4f}\")\n",
    "print(f\"MAE (shuffled): {result_leaky.details['mae_shuffled_avg']:.4f}\")\n",
    "print(f\"Improvement: {result_leaky.metric_value:.1%}\")\n",
    "print()\n",
    "print(f\"⚠️ LEAKAGE DETECTED!\")\n",
    "print(f\"  Clean improvement:  {result.metric_value:.1%}\")\n",
    "print(f\"  Leaky improvement:  {result_leaky.metric_value:.1%}\")\n",
    "print(f\"  Difference:         {result_leaky.metric_value - result.metric_value:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Walk-Forward CV with Gap Enforcement\n",
    "\n",
    "For **h-step ahead forecasting**, the gap between train and test must be ≥ h.\n",
    "\n",
    "Without gap enforcement:\n",
    "- Train ends at t=100\n",
    "- Test starts at t=101\n",
    "- But for h=12 forecasting, y[101] uses features from y[90]...y[100]\n",
    "- **LEAKAGE**: Test features overlap with training targets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 12  # 12-step ahead forecast\n",
    "\n",
    "# WITHOUT gap (WRONG for h-step)\n",
    "cv_no_gap = WalkForwardCV(n_splits=3, gap=0, test_size=horizon)\n",
    "\n",
    "# WITH gap (CORRECT)\n",
    "cv_with_gap = WalkForwardCV(n_splits=3, gap=horizon, test_size=horizon)\n",
    "\n",
    "print(\"WITHOUT Gap Enforcement (WRONG for h-step forecasting)\")\n",
    "print(\"=\" * 60)\n",
    "for info in cv_no_gap.get_split_info(X):\n",
    "    result = gate_temporal_boundary(\n",
    "        train_end_idx=info.train_end,\n",
    "        test_start_idx=info.test_start,\n",
    "        horizon=horizon,\n",
    "        gap=0,\n",
    "    )\n",
    "    status = \"✓ OK\" if result.status.value == \"PASS\" else \"✗ LEAKAGE!\"\n",
    "    print(f\"  Split {info.split_idx}: Train ends at {info.train_end}, \"\n",
    "          f\"Test starts at {info.test_start}, Gap={info.gap} → {status}\")\n",
    "\n",
    "print()\n",
    "print(\"WITH Gap Enforcement (CORRECT)\")\n",
    "print(\"=\" * 60)\n",
    "for info in cv_with_gap.get_split_info(X):\n",
    "    result = gate_temporal_boundary(\n",
    "        train_end_idx=info.train_end,\n",
    "        test_start_idx=info.test_start,\n",
    "        horizon=horizon,\n",
    "        gap=0,\n",
    "    )\n",
    "    status = \"✓ OK\" if result.status.value == \"PASS\" else \"✗ LEAKAGE!\"\n",
    "    print(f\"  Split {info.split_idx}: Train ends at {info.train_end}, \"\n",
    "          f\"Test starts at {info.test_start}, Gap={info.gap} → {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the split structure\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 6))\n",
    "\n",
    "for ax, cv, title in [\n",
    "    (axes[0], cv_no_gap, 'Without Gap (WRONG)'),\n",
    "    (axes[1], cv_with_gap, 'With Gap (CORRECT)'),\n",
    "]:\n",
    "    for i, info in enumerate(cv.get_split_info(X)):\n",
    "        # Training region\n",
    "        ax.barh(i, info.train_size, left=0, color='steelblue', \n",
    "                alpha=0.7, label='Train' if i == 0 else '')\n",
    "        # Gap region\n",
    "        ax.barh(i, info.gap, left=info.train_end, color='white', \n",
    "                edgecolor='gray', hatch='///', \n",
    "                label='Gap' if i == 0 else '')\n",
    "        # Test region\n",
    "        ax.barh(i, info.test_size, left=info.test_start, color='coral',\n",
    "                alpha=0.7, label='Test' if i == 0 else '')\n",
    "    \n",
    "    ax.set_xlabel('Time Index')\n",
    "    ax.set_ylabel('Split')\n",
    "    ax.set_title(title)\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.set_yticks(range(3))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Conformal Prediction Intervals\n",
    "\n",
    "Point predictions are insufficient for decision-making. Stakeholders need: \"How confident are you?\"\n",
    "\n",
    "**Conformal prediction** provides:\n",
    "- Distribution-free coverage guarantee\n",
    "- Finite-sample validity (not just asymptotic)\n",
    "- No parametric assumptions\n",
    "\n",
    "**Adaptive conformal** adjusts to distribution shift — critical for non-stationary time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Walk-forward predictions\n",
    "cv = WalkForwardCV(n_splits=5, window_type='expanding', test_size=50)\n",
    "\n",
    "all_preds = []\n",
    "all_actuals = []\n",
    "all_test_indices = []\n",
    "\n",
    "for train_idx, test_idx in cv.split(X):\n",
    "    model = Ridge(alpha=1.0)\n",
    "    model.fit(X[train_idx], y[train_idx])\n",
    "    preds = model.predict(X[test_idx])\n",
    "    \n",
    "    all_preds.extend(preds)\n",
    "    all_actuals.extend(y[test_idx])\n",
    "    all_test_indices.extend(test_idx)\n",
    "\n",
    "predictions = np.array(all_preds)\n",
    "actuals = np.array(all_actuals)\n",
    "test_indices = np.array(all_test_indices)\n",
    "\n",
    "print(f\"Walk-forward predictions: {len(predictions)} points\")\n",
    "print(f\"MAE: {mean_absolute_error(actuals, predictions):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply conformal prediction\n",
    "intervals, quality = walk_forward_conformal(\n",
    "    predictions=predictions,\n",
    "    actuals=actuals,\n",
    "    calibration_fraction=0.3,\n",
    "    alpha=0.10,  # 90% intervals\n",
    ")\n",
    "\n",
    "print(\"Conformal Prediction Results (90% intervals)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Calibration size: {quality['calibration_size']}\")\n",
    "print(f\"Holdout size: {quality['holdout_size']}\")\n",
    "print(f\"Calibrated quantile: {quality['quantile']:.4f}\")\n",
    "print()\n",
    "print(f\"Coverage: {quality['coverage']:.1%} (target: 90%)\")\n",
    "print(f\"Mean width: {quality['mean_width']:.4f}\")\n",
    "print(f\"Interval score: {quality['interval_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize prediction intervals\n",
    "cal_size = quality['calibration_size']\n",
    "holdout_indices = test_indices[cal_size:]\n",
    "holdout_actuals = actuals[cal_size:]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "\n",
    "# Original series\n",
    "ax.plot(series, 'lightgray', linewidth=0.5, label='Full series')\n",
    "\n",
    "# Prediction intervals\n",
    "ax.fill_between(\n",
    "    holdout_indices, \n",
    "    intervals.lower, \n",
    "    intervals.upper, \n",
    "    alpha=0.3, \n",
    "    color='steelblue',\n",
    "    label=f'90% CI (coverage: {quality[\"coverage\"]:.1%})'\n",
    ")\n",
    "\n",
    "# Point predictions\n",
    "ax.plot(holdout_indices, intervals.point, 'b-', linewidth=1, label='Predictions')\n",
    "\n",
    "# Actuals\n",
    "ax.scatter(holdout_indices, holdout_actuals, c='coral', s=10, alpha=0.7, label='Actuals')\n",
    "\n",
    "# Mark violations (actuals outside interval)\n",
    "violations = (holdout_actuals < intervals.lower) | (holdout_actuals > intervals.upper)\n",
    "ax.scatter(\n",
    "    holdout_indices[violations], \n",
    "    holdout_actuals[violations], \n",
    "    c='red', s=50, marker='x', linewidths=2,\n",
    "    label=f'Violations ({violations.sum()})'\n",
    ")\n",
    "\n",
    "ax.set_xlabel('Time Index')\n",
    "ax.set_ylabel('Value')\n",
    "ax.set_title('Conformal Prediction Intervals')\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Running Multiple Validation Gates\n",
    "\n",
    "TemporalCV gates follow **HALT > WARN > PASS** priority:\n",
    "- **HALT**: Stop and investigate (critical failure)\n",
    "- **WARN**: Proceed with caution (verify externally)\n",
    "- **PASS**: Validation passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run multiple gates on clean features\n",
    "model = Ridge(alpha=1.0)\n",
    "\n",
    "gates = [\n",
    "    gate_shuffled_target(\n",
    "        model=model,\n",
    "        X=X,\n",
    "        y=y,\n",
    "        n_shuffles=10,\n",
    "        threshold=0.95,\n",
    "        random_state=42,\n",
    "    ),\n",
    "    gate_temporal_boundary(\n",
    "        train_end_idx=350,\n",
    "        test_start_idx=362,  # Gap of 12\n",
    "        horizon=12,\n",
    "        gap=0,\n",
    "    ),\n",
    "]\n",
    "\n",
    "report = run_gates(gates)\n",
    "print(report.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Key Takeaways\n",
    "\n",
    "### 1. Shuffled Target Test\n",
    "- **If model beats shuffled baseline significantly → LEAKAGE**\n",
    "- Catches: rolling stats on full series, lookahead bias, off-by-one errors\n",
    "\n",
    "### 2. Walk-Forward CV\n",
    "- **Gap must be ≥ forecast horizon**\n",
    "- Without gap → test features overlap training targets\n",
    "\n",
    "### 3. Conformal Prediction\n",
    "- **Coverage guarantee without distributional assumptions**\n",
    "- Use adaptive conformal for non-stationary data\n",
    "\n",
    "### 4. Gate Priority\n",
    "- HALT > WARN > PASS\n",
    "- Always investigate HALT before deployment\n",
    "\n",
    "---\n",
    "\n",
    "**Resources**:\n",
    "- [temporalcv documentation](https://github.com/brandonmbehring-dev/temporalcv)\n",
    "- [Examples directory](https://github.com/brandonmbehring-dev/temporalcv/tree/main/examples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
