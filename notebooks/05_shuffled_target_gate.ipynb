{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": "# The Shuffled Target Gate: Definitive Leakage Detection\n\n## If Your Model Beats Shuffled Data, Something is Wrong\n\n---\n\n## \ud83d\udea8 If You Know sklearn But Not Time Series Leakage, Read This First\n\n**What you already know (from standard ML)**:\n- Feature engineering is about extracting predictive signals\n- If your model beats the baseline, you've built something useful\n- Cross-validation protects against overfitting\n\n**What's different with time series leakage**:\n\nIn time series, you can accidentally create features that **encode target position** instead of **predictive signal**:\n\n```python\n# LOOKS INNOCENT:\nX['rolling_mean'] = y.rolling(7).mean()  # Computed on FULL series\n\n# ACTUALLY LEAKY:\n# rolling_mean at t=100 uses y[94:101]\n# If y[100] is a test target, we've leaked test info into training!\n```\n\n**The shuffled target test detects this**:\n- Shuffle the target randomly \u2192 destroy time structure\n- If model STILL predicts well \u2192 features must encode position, not value\n- That's leakage!\n\n**What you'll learn:**\n1. Why permutation testing is the definitive test for feature-target leakage\n2. How to use `gate_signal_verification` with block vs IID permutation\n3. When to use effect_size (fast) vs permutation (rigorous) methods\n4. How to interpret HALT results and fix the underlying bugs\n\n**Prerequisites:** Notebooks 01, 04\n\n---"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from temporalcv.cv import WalkForwardCV\n",
    "from temporalcv.gates import gate_signal_verification, GateStatus\n",
    "\n",
    "np.random.seed(42)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate AR(1) process\n",
    "def generate_ar1(n=500, phi=0.9, sigma=1.0, seed=42):\n",
    "    \"\"\"Generate AR(1) process with specified autocorrelation.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    y = np.zeros(n)\n",
    "    y[0] = rng.normal(0, sigma / np.sqrt(1 - phi**2))\n",
    "    for t in range(1, n):\n",
    "        y[t] = phi * y[t-1] + sigma * rng.normal()\n",
    "    return y\n",
    "\n",
    "# Generate base series\n",
    "series = generate_ar1(n=500, phi=0.9, seed=42)\n",
    "print(f\"Generated AR(1) series with ACF(1) = {np.corrcoef(series[1:], series[:-1])[0,1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 1: The Problem \u2014 Features Can Encode Target Position\n",
    "\n",
    "**The trap:** When features are computed from the full series (before train/test split), they can inadvertently encode information about **where** in the series each observation falls.\n",
    "\n",
    "### Example: Leaky Features\n",
    "\n",
    "Consider these \"features\" that encode the target:\n",
    "```python\n",
    "# Feature 1: target + small noise\n",
    "X[:, 0] = y + noise\n",
    "\n",
    "# Feature 2: scaled target + noise  \n",
    "X[:, 1] = y * 0.5 + noise\n",
    "```\n",
    "\n",
    "These features encode the target value directly. A model trained on these will achieve impossibly good performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create clean features (legitimate lag features)\n",
    "def create_lag_features(series, n_lags=5):\n",
    "    \"\"\"Create clean lag features - no lookahead.\"\"\"\n",
    "    n = len(series)\n",
    "    X = np.column_stack([\n",
    "        np.concatenate([[np.nan]*lag, series[:-lag]]) \n",
    "        for lag in range(1, n_lags + 1)\n",
    "    ])\n",
    "    valid = ~np.isnan(X).any(axis=1)\n",
    "    return X[valid], series[valid]\n",
    "\n",
    "# Create clean features\n",
    "X_clean, y_clean = create_lag_features(series, n_lags=5)\n",
    "print(f\"Clean features: X shape = {X_clean.shape}\")\n",
    "\n",
    "# Create leaky features (encode target position)\n",
    "rng = np.random.default_rng(42)\n",
    "noise = rng.normal(0, 0.1, (len(y_clean), 3))\n",
    "\n",
    "X_leaky = np.column_stack([\n",
    "    y_clean + noise[:, 0],       # Feature 1: target + noise\n",
    "    y_clean * 0.5 + noise[:, 1], # Feature 2: scaled target + noise\n",
    "    noise[:, 2],                  # Feature 3: pure noise (legitimate)\n",
    "])\n",
    "\n",
    "print(f\"Leaky features: X shape = {X_leaky.shape}\")\n",
    "print(f\"\\nCorrelation between features and target:\")\n",
    "for i in range(X_leaky.shape[1]):\n",
    "    corr = np.corrcoef(X_leaky[:, i], y_clean)[0, 1]\n",
    "    status = \"LEAKED!\" if abs(corr) > 0.5 else \"OK\"\n",
    "    print(f\"  Feature {i+1}: r = {corr:.3f} {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "pokomvn483",
   "source": "# CRITICAL VISUALIZATION: Leaky vs Clean Features Heatmap\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Left: Clean features - correlation with target\nax = axes[0]\nax.set_title('\u2713 Clean Features (Legitimate Lags)\\nCorrelation with Target', fontsize=12, fontweight='bold', color='green')\n\n# Compute correlations for clean features\nclean_corrs = np.array([np.corrcoef(X_clean[:, i], y_clean)[0, 1] for i in range(X_clean.shape[1])])\nclean_labels = [f'y[t-{i+1}]' for i in range(X_clean.shape[1])]\n\n# Plot as horizontal bar\ncolors = ['green' if abs(c) < 0.5 else 'orange' if abs(c) < 0.8 else 'red' for c in clean_corrs]\nbars = ax.barh(clean_labels, clean_corrs, color=colors, edgecolor='black', alpha=0.7)\nax.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\nax.axvline(x=0.5, color='orange', linestyle='--', linewidth=1, alpha=0.7, label='Warning threshold')\nax.axvline(x=-0.5, color='orange', linestyle='--', linewidth=1, alpha=0.7)\nax.axvline(x=0.8, color='red', linestyle='--', linewidth=1, alpha=0.7, label='Danger threshold')\nax.axvline(x=-0.8, color='red', linestyle='--', linewidth=1, alpha=0.7)\nax.set_xlabel('Correlation with Target', fontsize=11)\nax.set_xlim(-1.1, 1.1)\nax.legend(loc='lower right', fontsize=9)\n\n# Annotate\nax.annotate('Lag correlations are\\nexpected and legitimate', \n            xy=(0.5, 0.2), xycoords='axes fraction',\n            fontsize=10, color='green', fontweight='bold',\n            bbox=dict(boxstyle='round', facecolor='honeydew', edgecolor='green'))\n\n# Right: Leaky features - correlation with target\nax = axes[1]\nax.set_title('\u274c Leaky Features (Target Encoded)\\nCorrelation with Target', fontsize=12, fontweight='bold', color='red')\n\n# Compute correlations for leaky features\nleaky_corrs = np.array([np.corrcoef(X_leaky[:, i], y_clean)[0, 1] for i in range(X_leaky.shape[1])])\nleaky_labels = ['target+noise', 'target*0.5+noise', 'pure_noise']\n\ncolors = ['green' if abs(c) < 0.5 else 'orange' if abs(c) < 0.8 else 'red' for c in leaky_corrs]\nbars = ax.barh(leaky_labels, leaky_corrs, color=colors, edgecolor='black', alpha=0.7)\nax.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\nax.axvline(x=0.5, color='orange', linestyle='--', linewidth=1, alpha=0.7)\nax.axvline(x=-0.5, color='orange', linestyle='--', linewidth=1, alpha=0.7)\nax.axvline(x=0.8, color='red', linestyle='--', linewidth=1, alpha=0.7)\nax.axvline(x=-0.8, color='red', linestyle='--', linewidth=1, alpha=0.7)\nax.set_xlabel('Correlation with Target', fontsize=11)\nax.set_xlim(-1.1, 1.1)\n\n# Annotate\nax.annotate('SUSPICIOUSLY HIGH!\\nFeatures encode target directly', \n            xy=(0.5, 0.6), xycoords='axes fraction',\n            fontsize=10, color='red', fontweight='bold',\n            bbox=dict(boxstyle='round', facecolor='lightyellow', edgecolor='red'))\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\u2605 Key Insight: Clean lag features have moderate correlation (expected for AR(1)).\")\nprint(\"  Leaky features have SUSPICIOUSLY HIGH correlation (>0.9) with target.\")\nprint(\"  Correlation > 0.8 is a red flag that warrants investigation.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on both feature sets and compare\n",
    "model = Ridge(alpha=1.0)\n",
    "\n",
    "# CV setup\n",
    "cv = WalkForwardCV(n_splits=5, window_type='expanding', test_size=50)\n",
    "\n",
    "# Evaluate clean features\n",
    "clean_maes = []\n",
    "for train_idx, test_idx in cv.split(X_clean):\n",
    "    model.fit(X_clean[train_idx], y_clean[train_idx])\n",
    "    preds = model.predict(X_clean[test_idx])\n",
    "    clean_maes.append(mean_absolute_error(y_clean[test_idx], preds))\n",
    "\n",
    "# Evaluate leaky features\n",
    "leaky_maes = []\n",
    "for train_idx, test_idx in cv.split(X_leaky):\n",
    "    model.fit(X_leaky[train_idx], y_clean[train_idx])\n",
    "    preds = model.predict(X_leaky[test_idx])\n",
    "    leaky_maes.append(mean_absolute_error(y_clean[test_idx], preds))\n",
    "\n",
    "print(\"CLEAN vs LEAKY FEATURES\")\n",
    "print(\"=\" * 55)\n",
    "print(f\"\\nClean features MAE:  {np.mean(clean_maes):.4f}\")\n",
    "print(f\"Leaky features MAE:  {np.mean(leaky_maes):.4f}  <-- Suspiciously low!\")\n",
    "print(f\"\\nImprovement: {(np.mean(clean_maes) - np.mean(leaky_maes)) / np.mean(clean_maes) * 100:.1f}%\")\n",
    "print(f\"\\nThe leaky features achieve impossibly good performance.\")\n",
    "print(f\"How do we DETECT this leakage systematically?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 2: Permutation Test Basics [T1]\n",
    "\n",
    "### The Key Insight\n",
    "\n",
    "**Shuffle the target** and see if the model can still predict it.\n",
    "\n",
    "- **If model beats shuffled target** \u2192 Features encode target position \u2192 LEAKAGE!\n",
    "- **If model fails on shuffled target** \u2192 Features capture legitimate patterns \u2192 SAFE\n",
    "\n",
    "### The Test\n",
    "\n",
    "1. Train model on original data, compute MAE\n",
    "2. Shuffle target many times, train model, compute MAE each time\n",
    "3. Calculate p-value: proportion of shuffled MAEs \u2264 original MAE\n",
    "4. If p-value < \u03b1 (typically 0.05) \u2192 HALT\n",
    "\n",
    "### Reference [T1]\n",
    "Phipson & Smyth (2010): p-value = (1 + count(shuffled \u2264 original)) / (1 + n_shuffles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the permutation test concept\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: Clean features\n",
    "ax = axes[0]\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# Simulate shuffled MAEs for clean features\n",
    "original_mae_clean = np.mean(clean_maes)\n",
    "shuffled_maes_clean = []\n",
    "for _ in range(100):\n",
    "    y_shuffled = rng.permutation(y_clean)\n",
    "    maes = []\n",
    "    for train_idx, test_idx in cv.split(X_clean):\n",
    "        model.fit(X_clean[train_idx], y_shuffled[train_idx])\n",
    "        preds = model.predict(X_clean[test_idx])\n",
    "        maes.append(mean_absolute_error(y_shuffled[test_idx], preds))\n",
    "    shuffled_maes_clean.append(np.mean(maes))\n",
    "\n",
    "ax.hist(shuffled_maes_clean, bins=20, alpha=0.7, color='steelblue', \n",
    "        edgecolor='black', label='Shuffled MAEs')\n",
    "ax.axvline(x=original_mae_clean, color='green', linestyle='--', linewidth=2,\n",
    "           label=f'Original MAE = {original_mae_clean:.3f}')\n",
    "ax.set_xlabel('MAE', fontsize=11)\n",
    "ax.set_ylabel('Count', fontsize=11)\n",
    "ax.set_title('Clean Features: Original MAE Within Shuffled Distribution\\n(No Leakage)',\n",
    "             fontsize=12, fontweight='bold', color='green')\n",
    "ax.legend()\n",
    "\n",
    "# Right: Leaky features\n",
    "ax = axes[1]\n",
    "original_mae_leaky = np.mean(leaky_maes)\n",
    "shuffled_maes_leaky = []\n",
    "for _ in range(100):\n",
    "    y_shuffled = rng.permutation(y_clean)\n",
    "    maes = []\n",
    "    for train_idx, test_idx in cv.split(X_leaky):\n",
    "        model.fit(X_leaky[train_idx], y_shuffled[train_idx])\n",
    "        preds = model.predict(X_leaky[test_idx])\n",
    "        maes.append(mean_absolute_error(y_shuffled[test_idx], preds))\n",
    "    shuffled_maes_leaky.append(np.mean(maes))\n",
    "\n",
    "ax.hist(shuffled_maes_leaky, bins=20, alpha=0.7, color='steelblue',\n",
    "        edgecolor='black', label='Shuffled MAEs')\n",
    "ax.axvline(x=original_mae_leaky, color='red', linestyle='--', linewidth=2,\n",
    "           label=f'Original MAE = {original_mae_leaky:.3f}')\n",
    "ax.set_xlabel('MAE', fontsize=11)\n",
    "ax.set_ylabel('Count', fontsize=11)\n",
    "ax.set_title('Leaky Features: Original MAE BEATS Shuffled Distribution\\n(LEAKAGE DETECTED!)',\n",
    "             fontsize=12, fontweight='bold', color='red')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate p-values\n",
    "pvalue_clean = (1 + sum(s <= original_mae_clean for s in shuffled_maes_clean)) / (1 + len(shuffled_maes_clean))\n",
    "pvalue_leaky = (1 + sum(s <= original_mae_leaky for s in shuffled_maes_leaky)) / (1 + len(shuffled_maes_leaky))\n",
    "\n",
    "print(f\"\\nP-values (Phipson & Smyth formula):\")\n",
    "print(f\"  Clean features: p = {pvalue_clean:.4f} \u2192 {'PASS' if pvalue_clean >= 0.05 else 'HALT'}\")\n",
    "print(f\"  Leaky features: p = {pvalue_leaky:.4f} \u2192 {'PASS' if pvalue_leaky >= 0.05 else 'HALT'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 3: Using `gate_signal_verification`\n",
    "\n",
    "temporalcv provides `gate_signal_verification` to run this test automatically.\n",
    "\n",
    "### Key Parameters\n",
    "\n",
    "| Parameter | Default | Description |\n",
    "|-----------|---------|-------------|\n",
    "| `method` | \"permutation\" | \"permutation\" for p-value, \"effect_size\" for quick check |\n",
    "| `n_shuffles` | 100 (perm) / 5 (effect) | Number of shuffle iterations |\n",
    "| `permutation` | \"block\" | \"block\" for time series, \"iid\" for standard |\n",
    "| `alpha` | 0.05 | Significance level (permutation mode) |\n",
    "| `strict` | False | If True, uses \u2265199 shuffles for p < 0.005 resolution |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate gate_signal_verification\n",
    "print(\"gate_signal_verification Demo\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "model = Ridge(alpha=1.0)\n",
    "\n",
    "# Test clean features\n",
    "print(\"\\n1. Clean Features (Legitimate Lags):\")\n",
    "result_clean = gate_signal_verification(\n",
    "    model=model,\n",
    "    X=X_clean,\n",
    "    y=y_clean,\n",
    "    method='permutation',\n",
    "    n_shuffles=100,  # For permutation mode\n",
    "    random_state=42\n",
    ")\n",
    "print(f\"   Status: {result_clean.status.value}\")\n",
    "print(f\"   p-value: {result_clean.details.get('pvalue', 'N/A'):.4f}\")\n",
    "print(f\"   Message: {result_clean.message}\")\n",
    "\n",
    "# Test leaky features\n",
    "print(\"\\n2. Leaky Features (Target Encoded):\")\n",
    "result_leaky = gate_signal_verification(\n",
    "    model=model,\n",
    "    X=X_leaky,\n",
    "    y=y_clean,\n",
    "    method='permutation',\n",
    "    n_shuffles=100,\n",
    "    random_state=42\n",
    ")\n",
    "print(f\"   Status: {result_leaky.status.value}\")\n",
    "print(f\"   p-value: {result_leaky.details.get('pvalue', 'N/A'):.4f}\")\n",
    "print(f\"   Message: {result_leaky.message}\")\n",
    "if result_leaky.recommendation:\n",
    "    print(f\"   Recommendation: {result_leaky.recommendation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 4: Block vs IID Permutation [T1]\n",
    "\n",
    "### The Problem with IID Shuffling\n",
    "\n",
    "Standard (IID) shuffling destroys **all** temporal structure. For persistent time series:\n",
    "- The shuffled target is essentially white noise\n",
    "- Any model with legitimate predictive ability should beat white noise\n",
    "- This produces **false positives** (HALT when there's no leakage)\n",
    "\n",
    "### The Solution: Block Permutation [T1]\n",
    "\n",
    "Block permutation:\n",
    "1. Divide series into blocks of size $b \\approx n^{1/3}$\n",
    "2. Shuffle the blocks (not individual observations)\n",
    "3. Preserves local autocorrelation structure\n",
    "\n",
    "**Reference [T1]**: Kunsch (1989), Politis & Romano (1994)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize block vs IID permutation\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Original series (subset)\n",
    "t = np.arange(100)\n",
    "original = series[:100]\n",
    "\n",
    "axes[0].plot(t, original, 'b-', linewidth=1.5)\n",
    "axes[0].set_title('Original Series\\n(Autocorrelated)', fontsize=11, fontweight='bold')\n",
    "axes[0].set_xlabel('Time')\n",
    "axes[0].set_ylabel('Value')\n",
    "\n",
    "# IID permutation\n",
    "rng = np.random.default_rng(42)\n",
    "iid_shuffled = rng.permutation(original)\n",
    "axes[1].plot(t, iid_shuffled, 'r-', linewidth=1.5)\n",
    "axes[1].set_title('IID Shuffled\\n(Structure Destroyed)', fontsize=11, fontweight='bold', color='red')\n",
    "axes[1].set_xlabel('Time')\n",
    "axes[1].set_ylabel('Value')\n",
    "\n",
    "# Block permutation (block_size = 10)\n",
    "block_size = 10\n",
    "n_blocks = len(original) // block_size\n",
    "blocks = [original[i*block_size:(i+1)*block_size] for i in range(n_blocks)]\n",
    "rng.shuffle(blocks)\n",
    "block_shuffled = np.concatenate(blocks)\n",
    "\n",
    "axes[2].plot(np.arange(len(block_shuffled)), block_shuffled, 'g-', linewidth=1.5)\n",
    "axes[2].set_title(f'Block Shuffled (b={block_size})\\n(Local Structure Preserved)', \n",
    "                  fontsize=11, fontweight='bold', color='green')\n",
    "axes[2].set_xlabel('Time')\n",
    "axes[2].set_ylabel('Value')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show ACF comparison\n",
    "print(\"\\nAutocorrelation at lag 1:\")\n",
    "print(f\"  Original:      {np.corrcoef(original[1:], original[:-1])[0,1]:.3f}\")\n",
    "print(f\"  IID Shuffled:  {np.corrcoef(iid_shuffled[1:], iid_shuffled[:-1])[0,1]:.3f} (destroyed)\")\n",
    "print(f\"  Block Shuffled: {np.corrcoef(block_shuffled[1:], block_shuffled[:-1])[0,1]:.3f} (preserved)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare block vs IID permutation results\n",
    "print(\"Block vs IID Permutation Comparison\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create legitimate features for a persistent series\n",
    "high_persist = generate_ar1(n=400, phi=0.95, seed=123)\n",
    "X_legit, y_legit = create_lag_features(high_persist, n_lags=5)\n",
    "\n",
    "model = Ridge(alpha=1.0)\n",
    "\n",
    "# Test with block permutation (correct for time series)\n",
    "print(\"\\n1. Block Permutation (preserves autocorrelation):\")\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    result_block = gate_signal_verification(\n",
    "        model=model,\n",
    "        X=X_legit,\n",
    "        y=y_legit,\n",
    "        method='permutation',\n",
    "        permutation='block',\n",
    "        n_shuffles=100,\n",
    "        random_state=42\n",
    "    )\n",
    "print(f\"   Status: {result_block.status.value}\")\n",
    "print(f\"   p-value: {result_block.details.get('pvalue', 'N/A'):.4f}\")\n",
    "\n",
    "# Test with IID permutation (may produce false positive)\n",
    "print(\"\\n2. IID Permutation (destroys autocorrelation):\")\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    result_iid = gate_signal_verification(\n",
    "        model=model,\n",
    "        X=X_legit,\n",
    "        y=y_legit,\n",
    "        method='permutation',\n",
    "        permutation='iid',\n",
    "        n_shuffles=100,\n",
    "        random_state=42\n",
    "    )\n",
    "print(f\"   Status: {result_iid.status.value}\")\n",
    "print(f\"   p-value: {result_iid.details.get('pvalue', 'N/A'):.4f}\")\n",
    "\n",
    "print(\"\\n[T1] Block permutation is the correct choice for time series.\")\n",
    "print(\"     IID permutation may flag legitimate models as leaky.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 5: Effect Size vs Permutation Methods\n",
    "\n",
    "### Two Modes for Different Use Cases\n",
    "\n",
    "| Method | Speed | Rigor | Use Case |\n",
    "|--------|-------|-------|----------|\n",
    "| `effect_size` | Fast (5 shuffles) | Heuristic | Development, quick checks |\n",
    "| `permutation` | Slower (100+ shuffles) | Statistical p-value | Publication, final validation |\n",
    "\n",
    "### Effect Size Mode\n",
    "- Computes: `improvement_ratio = 1 - (model_mae / mean_shuffled_mae)`\n",
    "- HALT if: `improvement_ratio > threshold` (default 5%)\n",
    "- Fast but heuristic\n",
    "\n",
    "### Permutation Mode [T1]\n",
    "- Computes exact p-value: `(1 + count(shuffled \u2264 original)) / (1 + n_shuffles)`\n",
    "- HALT if: `p-value < alpha` (default 0.05)\n",
    "- Statistically rigorous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare effect_size vs permutation methods\n",
    "print(\"Effect Size vs Permutation Methods\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "model = Ridge(alpha=1.0)\n",
    "\n",
    "# Test on leaky features with both methods\n",
    "print(\"\\nTesting LEAKY features:\")\n",
    "\n",
    "# Effect size (fast)\n",
    "import time\n",
    "start = time.time()\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    result_effect = gate_signal_verification(\n",
    "        model=model,\n",
    "        X=X_leaky,\n",
    "        y=y_clean,\n",
    "        method='effect_size',\n",
    "        random_state=42\n",
    "    )\n",
    "time_effect = time.time() - start\n",
    "\n",
    "print(f\"\\n1. Effect Size Method:\")\n",
    "print(f\"   Status: {result_effect.status.value}\")\n",
    "print(f\"   Improvement: {result_effect.details.get('improvement_ratio', 0)*100:.1f}%\")\n",
    "print(f\"   Time: {time_effect:.2f}s\")\n",
    "\n",
    "# Permutation (rigorous)\n",
    "start = time.time()\n",
    "result_perm = gate_signal_verification(\n",
    "    model=model,\n",
    "    X=X_leaky,\n",
    "    y=y_clean,\n",
    "    method='permutation',\n",
    "    n_shuffles=100,\n",
    "    random_state=42\n",
    ")\n",
    "time_perm = time.time() - start\n",
    "\n",
    "print(f\"\\n2. Permutation Method:\")\n",
    "print(f\"   Status: {result_perm.status.value}\")\n",
    "print(f\"   p-value: {result_perm.details.get('pvalue', 'N/A'):.4f}\")\n",
    "print(f\"   Time: {time_perm:.2f}s\")\n",
    "\n",
    "print(f\"\\nRecommendation:\")\n",
    "print(f\"  - Use effect_size during development (fast feedback)\")\n",
    "print(f\"  - Use permutation for final validation (statistically rigorous)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate strict mode for publication\n",
    "print(\"Strict Mode for Publication\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nStrict mode ensures adequate statistical power:\")\n",
    "print(\"- Overrides n_shuffles to \u2265199\")\n",
    "print(\"- Provides p-value resolution of 0.005\")\n",
    "print(\"- Recommended for publication-quality results\")\n",
    "\n",
    "# Without strict mode\n",
    "print(\"\\nWithout strict (n_shuffles=100):\")\n",
    "result_normal = gate_signal_verification(\n",
    "    model=model,\n",
    "    X=X_clean,\n",
    "    y=y_clean,\n",
    "    method='permutation',\n",
    "    n_shuffles=100,\n",
    "    strict=False,\n",
    "    random_state=42\n",
    ")\n",
    "print(f\"   n_shuffles used: {result_normal.details.get('n_shuffles', 50)}\")\n",
    "print(f\"   Min p-value resolution: 1/{50+1} \u2248 {1/51:.4f}\")\n",
    "\n",
    "# With strict mode\n",
    "print(\"\\nWith strict=True:\")\n",
    "result_strict = gate_signal_verification(\n",
    "    model=model,\n",
    "    X=X_clean,\n",
    "    y=y_clean,\n",
    "    method='permutation',\n",
    "    n_shuffles=100,  # Will be overridden\n",
    "    strict=True,\n",
    "    random_state=42\n",
    ")\n",
    "print(f\"   n_shuffles used: {result_strict.details.get('n_shuffles', 199)}\")\n",
    "print(f\"   Min p-value resolution: 1/{199+1} = {1/200:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 6: Interpreting HALT Results\n",
    "\n",
    "When `gate_signal_verification` returns HALT, your features encode target position.\n",
    "\n",
    "### Common Causes\n",
    "\n",
    "1. **Direct target leakage**: Features computed from target values\n",
    "2. **Rolling stats on full series**: Statistics computed before train/test split\n",
    "3. **Feature selection on target**: Using target to select features\n",
    "4. **Centered windows**: Using future values in window calculations\n",
    "\n",
    "### Debugging Steps\n",
    "\n",
    "1. Check feature-target correlations\n",
    "2. Review feature engineering pipeline\n",
    "3. Ensure train/test separation happens BEFORE feature computation\n",
    "4. Use backward-only windows for rolling statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging workflow when HALT is triggered\n",
    "def debug_leakage(X, y, feature_names=None):\n",
    "    \"\"\"Debug potential feature-target leakage.\"\"\"\n",
    "    if feature_names is None:\n",
    "        feature_names = [f\"Feature_{i}\" for i in range(X.shape[1])]\n",
    "    \n",
    "    print(\"LEAKAGE DEBUGGING REPORT\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Step 1: Check correlations\n",
    "    print(\"\\n1. Feature-Target Correlations:\")\n",
    "    print(\"-\" * 40)\n",
    "    suspicious = []\n",
    "    for i in range(X.shape[1]):\n",
    "        corr = np.corrcoef(X[:, i], y)[0, 1]\n",
    "        status = \"SUSPICIOUS!\" if abs(corr) > 0.8 else (\"Warning\" if abs(corr) > 0.5 else \"OK\")\n",
    "        print(f\"   {feature_names[i]}: r = {corr:+.3f} [{status}]\")\n",
    "        if abs(corr) > 0.5:\n",
    "            suspicious.append(feature_names[i])\n",
    "    \n",
    "    # Step 2: Recommendations\n",
    "    print(f\"\\n2. Recommendations:\")\n",
    "    print(\"-\" * 40)\n",
    "    if suspicious:\n",
    "        print(f\"   Investigate these features: {suspicious}\")\n",
    "        print(f\"   \\n   Possible causes:\")\n",
    "        print(f\"   - Feature computed from target values\")\n",
    "        print(f\"   - Rolling statistics on full series\")\n",
    "        print(f\"   - Centered window including future\")\n",
    "    else:\n",
    "        print(f\"   No obviously suspicious correlations found.\")\n",
    "        print(f\"   Check for subtle leakage in feature engineering pipeline.\")\n",
    "    \n",
    "    return suspicious\n",
    "\n",
    "# Run debugging on leaky features\n",
    "suspicious = debug_leakage(\n",
    "    X_leaky, y_clean, \n",
    "    feature_names=['target+noise', 'target*0.5+noise', 'pure_noise']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Pitfall Section\n",
    "\n",
    "### Pitfall 1: n_shuffles Too Low\n",
    "\n",
    "```python\n",
    "# WRONG: Too few shuffles for statistical power\n",
    "result = gate_signal_verification(model, X, y, n_shuffles=5)  # Can't get p < 0.1!\n",
    "\n",
    "# RIGHT: Enough shuffles for desired significance\n",
    "result = gate_signal_verification(model, X, y, n_shuffles=100)  # Can get p < 0.01\n",
    "\n",
    "# BETTER: Use strict mode for publication\n",
    "result = gate_signal_verification(model, X, y, strict=True)  # \u2265199 shuffles\n",
    "```\n",
    "\n",
    "**Rule of thumb [T1]:**\n",
    "- n_shuffles \u2265 19 for p < 0.05\n",
    "- n_shuffles \u2265 100 for p < 0.01\n",
    "- n_shuffles \u2265 199 for p < 0.005 (strict mode)\n",
    "\n",
    "### Pitfall 2: Using IID Permutation on Time Series\n",
    "\n",
    "```python\n",
    "# WRONG: IID permutation on autocorrelated data\n",
    "result = gate_signal_verification(model, X, y, permutation='iid')  # False positives!\n",
    "\n",
    "# RIGHT: Block permutation preserves local structure\n",
    "result = gate_signal_verification(model, X, y, permutation='block')  # Default\n",
    "```\n",
    "\n",
    "### Pitfall 3: Ignoring HALT\n",
    "\n",
    "```python\n",
    "# WRONG: Ignore the warning\n",
    "result = gate_signal_verification(model, X, y)\n",
    "if result.status == GateStatus.HALT:\n",
    "    pass  # Hope for the best?\n",
    "\n",
    "# RIGHT: Investigate and fix\n",
    "result = gate_signal_verification(model, X, y)\n",
    "if result.status == GateStatus.HALT:\n",
    "    raise ValueError(f\"Leakage detected: {result.message}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate the n_shuffles pitfall\n",
    "print(\"Pitfall: n_shuffles and p-value Resolution\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nMinimum p-value achievable with different n_shuffles:\")\n",
    "print(\"-\" * 40)\n",
    "for n in [5, 10, 19, 50, 99, 199]:\n",
    "    min_p = 1 / (n + 1)\n",
    "    can_achieve = \"p < 0.05\" if min_p < 0.05 else \"p < 0.1\" if min_p < 0.1 else \"p \u2265 0.1\"\n",
    "    print(f\"   n_shuffles={n:3d} \u2192 min p = {min_p:.4f} ({can_achieve})\")\n",
    "\n",
    "print(\"\\n[T1] Per Phipson & Smyth (2010): p = (1 + count) / (1 + n_shuffles)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Complete Example: Validation Pipeline\n",
    "\n",
    "Here's how to integrate `gate_signal_verification` into your validation workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": "def validate_features(model, X, y, feature_names=None, strict=False):\n    \"\"\"\n    Validate features for leakage using shuffled target test.\n    \n    Parameters\n    ----------\n    model : estimator\n        sklearn-compatible model\n    X : array-like\n        Features\n    y : array-like\n        Target\n    feature_names : list, optional\n        Names for debugging\n    strict : bool, default=False\n        If True, use publication-quality settings\n        \n    Returns\n    -------\n    dict\n        Validation results\n    \"\"\"\n    # Run gate\n    result = gate_signal_verification(\n        model=model,\n        X=X,\n        y=y,\n        method='permutation',\n        permutation='block',\n        strict=strict,\n        random_state=42\n    )\n    \n    # Build report - using current API keys (mae_real, mae_shuffled_avg)\n    report = {\n        'status': result.status.value,\n        'passed': result.status == GateStatus.PASS,\n        'pvalue': result.details.get('pvalue'),\n        'mae_real': result.details.get('mae_real'),\n        'mae_shuffled_avg': result.details.get('mae_shuffled_avg'),\n        'message': result.message,\n    }\n    \n    # If failed, add debugging info\n    if result.status == GateStatus.HALT:\n        report['suspicious_features'] = debug_leakage(X, y, feature_names)\n    \n    return report\n\n# Test on clean and leaky features\nprint(\"FEATURE VALIDATION RESULTS\")\nprint(\"=\" * 60)\n\nmodel = Ridge(alpha=1.0)\n\nprint(\"\\n1. Clean Features:\")\nreport_clean = validate_features(\n    model, X_clean, y_clean,\n    feature_names=[f'lag_{i}' for i in range(1, 6)]\n)\nprint(f\"   Status: {report_clean['status']}\")\nprint(f\"   Passed: {report_clean['passed']}\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"\\n2. Leaky Features:\")\nreport_leaky = validate_features(\n    model, X_leaky, y_clean,\n    feature_names=['target+noise', 'target*0.5+noise', 'pure_noise']\n)\nprint(f\"\\n   Status: {report_leaky['status']}\")\nprint(f\"   Passed: {report_leaky['passed']}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Insights\n",
    "\n",
    "### 1. The Shuffled Target Test is Definitive [T1]\n",
    "If your model beats a shuffled target, your features encode target position. Period.\n",
    "\n",
    "### 2. Use Block Permutation for Time Series [T1]\n",
    "Block permutation preserves local autocorrelation. IID permutation produces false positives.\n",
    "\n",
    "### 3. n_shuffles Determines p-value Resolution [T1]\n",
    "- n_shuffles \u2265 19 for p < 0.05\n",
    "- n_shuffles \u2265 100 for p < 0.01\n",
    "- Use `strict=True` for publication\n",
    "\n",
    "### 4. Effect Size for Development, Permutation for Production\n",
    "Quick checks during development, rigorous testing before deployment.\n",
    "\n",
    "### 5. HALT Means Stop and Investigate\n",
    "Never ignore a HALT. Find and fix the leakage source.\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- **06_feature_engineering_pitfalls.ipynb**: Safe lag features and rolling stats\n",
    "- **07_threshold_leakage.ipynb**: Regime and percentile computation\n",
    "- **08_validation_workflow.ipynb**: Complete HALT/WARN/PASS pipeline\n",
    "\n",
    "---\n",
    "\n",
    "*\"If your model beats shuffled data, it's not skill \u2014 it's leakage.\"*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
